{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "785ed6c9",
   "metadata": {},
   "source": [
    "# Moir√© Lattice Reconstruction - Environment Setup\n",
    "\n",
    "This notebook sets up the environment and tests the ML framework for reconstructing grayscale images as multiple moir√© lattices.\n",
    "\n",
    "## Project Overview\n",
    "- **Input**: Grayscale images\n",
    "- **Output**: Array of Bravais lattices with parameters (base vectors, hole size)\n",
    "- **Approach**: Both algorithmic (FFT-based) and learned (CNN) methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c768dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the ML environment\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "# Run the environment test script\n",
    "result = subprocess.run([sys.executable, 'test_ml_environment.py'], \n",
    "                       capture_output=True, text=True)\n",
    "\n",
    "print(result.stdout)\n",
    "if result.stderr:\n",
    "    print(\"STDERR:\")\n",
    "    print(result.stderr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "767200c5",
   "metadata": {},
   "source": [
    "## Basic Imports and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a12f2ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import fft\n",
    "import cv2\n",
    "\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "print(f\"NumPy version: {np.__version__}\")\n",
    "\n",
    "# Check GPU availability\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "print(f\"GPUs available: {len(gpus)}\")\n",
    "for gpu in gpus:\n",
    "    print(f\"  {gpu}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fdcb01b",
   "metadata": {},
   "source": [
    "## 1. Algorithmic Approach: FFT-based Peak Extraction\n",
    "\n",
    "This implements the baseline approach described in the instructions:\n",
    "1. Compute 2D FFT of target image\n",
    "2. Find magnitude peaks in frequency domain\n",
    "3. Map peaks to lattice parameters\n",
    "4. Render synthetic image\n",
    "5. Iterative refinement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d749eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_test_moire_image(size=64, num_lattices=20):\n",
    "    \"\"\"Create a synthetic test image with multiple moir√© patterns\"\"\"\n",
    "    x = np.linspace(0, 2*np.pi, size)\n",
    "    y = np.linspace(0, 2*np.pi, size)\n",
    "    X, Y = np.meshgrid(x, y)\n",
    "    \n",
    "    image = np.zeros((size, size))\n",
    "    \n",
    "    # Add multiple lattice patterns\n",
    "    angles = np.linspace(0, np.pi, num_lattices, endpoint=False)\n",
    "    frequencies = [2, 3, 4]\n",
    "    \n",
    "    for i, (angle, freq) in enumerate(zip(angles, frequencies)):\n",
    "        # Rotate coordinate system\n",
    "        X_rot = X * np.cos(angle) - Y * np.sin(angle)\n",
    "        Y_rot = X * np.sin(angle) + Y * np.cos(angle)\n",
    "        \n",
    "        # Add lattice pattern\n",
    "        amplitude = 0.3 / (i + 1)  # Decreasing amplitude\n",
    "        pattern = amplitude * np.sin(freq * X_rot) * np.cos(freq * Y_rot)\n",
    "        image += pattern\n",
    "    \n",
    "    # Normalize to [0, 1]\n",
    "    image = (image - image.min()) / (image.max() - image.min())\n",
    "    return image\n",
    "\n",
    "# Create test image\n",
    "test_image = create_test_moire_image()\n",
    "\n",
    "# Display\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(test_image, cmap='gray')\n",
    "plt.title('Test Moir√© Image')\n",
    "plt.colorbar()\n",
    "\n",
    "# Compute and display FFT\n",
    "fft_result = np.fft.fft2(test_image)\n",
    "fft_magnitude = np.abs(np.fft.fftshift(fft_result))\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(np.log(fft_magnitude + 1), cmap='viridis')\n",
    "plt.title('FFT Magnitude (log scale)')\n",
    "plt.colorbar()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Test image shape: {test_image.shape}\")\n",
    "print(f\"FFT result shape: {fft_result.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "562fc74c",
   "metadata": {},
   "source": [
    "## 2. Neural Network Approach: CNN Encoder\n",
    "\n",
    "This implements the learned approach:\n",
    "- CNN encoder: grayscale image ‚Üí feature vector\n",
    "- Regressor head: outputs lattice parameters (Œ∏, |k|, œÜ, A)\n",
    "- Differentiable renderer for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9561ab7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_lattice_cnn(input_shape=(64, 64, 1), num_lattices=8):\n",
    "    \"\"\"Create CNN for image-to-lattice parameter regression\"\"\"\n",
    "    \n",
    "    inputs = tf.keras.Input(shape=input_shape)\n",
    "    \n",
    "    # CNN Encoder\n",
    "    x = tf.keras.layers.Conv2D(32, (3, 3), activation='relu', padding='same')(inputs)\n",
    "    x = tf.keras.layers.MaxPooling2D((2, 2))(x)\n",
    "    \n",
    "    x = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = tf.keras.layers.MaxPooling2D((2, 2))(x)\n",
    "    \n",
    "    x = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = tf.keras.layers.MaxPooling2D((2, 2))(x)\n",
    "    \n",
    "    x = tf.keras.layers.Conv2D(256, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "    \n",
    "    # Dense layers\n",
    "    x = tf.keras.layers.Dense(512, activation='relu')(x)\n",
    "    x = tf.keras.layers.Dropout(0.5)(x)\n",
    "    x = tf.keras.layers.Dense(256, activation='relu')(x)\n",
    "    x = tf.keras.layers.Dropout(0.3)(x)\n",
    "    \n",
    "    # Output: num_lattices √ó 4 parameters (theta, |k|, phi, amplitude)\n",
    "    outputs = tf.keras.layers.Dense(num_lattices * 4, activation='linear')(x)\n",
    "    \n",
    "    model = tf.keras.Model(inputs, outputs)\n",
    "    return model\n",
    "\n",
    "# Create model\n",
    "model = create_lattice_cnn()\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "\n",
    "# Model summary\n",
    "model.summary()\n",
    "\n",
    "# Test with dummy data\n",
    "dummy_input = np.random.random((1, 64, 64, 1))\n",
    "output = model.predict(dummy_input, verbose=0)\n",
    "\n",
    "print(f\"\\nModel test:\")\n",
    "print(f\"Input shape: {dummy_input.shape}\")\n",
    "print(f\"Output shape: {output.shape}\")\n",
    "print(f\"Output represents: {output.shape[1]//4} lattices √ó 4 parameters each\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbf0dfdc",
   "metadata": {},
   "source": [
    "## 3. Differentiable Renderer\n",
    "\n",
    "This implements a differentiable renderer that can synthesize images from lattice parameters, enabling end-to-end training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9ba92c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def differentiable_renderer(lattice_params, image_size=64):\n",
    "    \"\"\"\n",
    "    Render an image from lattice parameters\n",
    "    \n",
    "    Args:\n",
    "        lattice_params: tensor of shape (batch_size, num_lattices * 4)\n",
    "                       where each lattice has (theta, |k|, phi, amplitude)\n",
    "        image_size: size of output image\n",
    "    \n",
    "    Returns:\n",
    "        rendered images of shape (batch_size, image_size, image_size, 1)\n",
    "    \"\"\"\n",
    "    batch_size = tf.shape(lattice_params)[0]\n",
    "    num_lattices = tf.shape(lattice_params)[1] // 4\n",
    "    \n",
    "    # Reshape parameters\n",
    "    params = tf.reshape(lattice_params, (batch_size, num_lattices, 4))\n",
    "    \n",
    "    # Create coordinate grid\n",
    "    x = tf.linspace(0., 2*np.pi, image_size)\n",
    "    y = tf.linspace(0., 2*np.pi, image_size)\n",
    "    X, Y = tf.meshgrid(x, y)\n",
    "    coords = tf.stack([X, Y], axis=-1)  # (image_size, image_size, 2)\n",
    "    \n",
    "    # Initialize output\n",
    "    images = tf.zeros((batch_size, image_size, image_size, 1))\n",
    "    \n",
    "    # Add each lattice contribution\n",
    "    for i in range(num_lattices):\n",
    "        theta = params[:, i, 0]  # (batch_size,)\n",
    "        k_mag = params[:, i, 1]  # (batch_size,)\n",
    "        phi = params[:, i, 2]    # (batch_size,)\n",
    "        amplitude = params[:, i, 3]  # (batch_size,)\n",
    "        \n",
    "        # Compute k vector\n",
    "        kx = k_mag * tf.cos(theta)  # (batch_size,)\n",
    "        ky = k_mag * tf.sin(theta)  # (batch_size,)\n",
    "        \n",
    "        # Broadcast for computation\n",
    "        kx = kx[:, None, None, None]  # (batch_size, 1, 1, 1)\n",
    "        ky = ky[:, None, None, None]  # (batch_size, 1, 1, 1)\n",
    "        phi = phi[:, None, None, None]  # (batch_size, 1, 1, 1)\n",
    "        amplitude = amplitude[:, None, None, None]  # (batch_size, 1, 1, 1)\n",
    "        \n",
    "        # Compute phase\n",
    "        phase = kx * X[None, :, :, None] + ky * Y[None, :, :, None] + phi\n",
    "        \n",
    "        # Add lattice contribution\n",
    "        contribution = amplitude * tf.cos(phase)\n",
    "        images += contribution\n",
    "    \n",
    "    return images\n",
    "\n",
    "# Test the renderer\n",
    "test_params = tf.constant([[1.0, 2.0, 0.0, 0.5,  # First lattice: theta=1, |k|=2, phi=0, amp=0.5\n",
    "                           0.5, 3.0, np.pi/4, 0.3]])  # Second lattice\n",
    "\n",
    "rendered = differentiable_renderer(test_params, image_size=64)\n",
    "\n",
    "plt.figure(figsize=(6, 5))\n",
    "plt.imshow(rendered[0, :, :, 0], cmap='gray')\n",
    "plt.title('Rendered Image from Lattice Parameters')\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Rendered image shape: {rendered.shape}\")\n",
    "print(f\"Parameters used: {test_params.numpy()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dfd7784",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "1. **Generate Training Data**: Create synthetic datasets with known lattice parameters\n",
    "2. **Train the Model**: Use the differentiable renderer for end-to-end training\n",
    "3. **Implement FFT Baseline**: For comparison and initialization\n",
    "4. **Evaluation**: Compare reconstruction quality and parameter recovery accuracy\n",
    "5. **Real Image Testing**: Test on actual grayscale images\n",
    "\n",
    "The environment is now ready for moir√© lattice reconstruction research!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8037eea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "def lattice_points_in_region(a1, a2, region_size):\n",
    "    \"\"\"\n",
    "    Generate lattice points within a square region\n",
    "    \n",
    "    Args:\n",
    "        a1, a2: base vectors (2D)\n",
    "        region_size: size of the square region\n",
    "    \n",
    "    Returns:\n",
    "        array of lattice points (N, 2)\n",
    "    \"\"\"\n",
    "    # Determine how many lattice cells we need in each direction\n",
    "    max_n = int(np.ceil(region_size / min(np.linalg.norm(a1), np.linalg.norm(a2)))) + 2\n",
    "    \n",
    "    points = []\n",
    "    for n in range(-max_n, max_n + 1):\n",
    "        for m in range(-max_n, max_n + 1):\n",
    "            point = n * a1 + m * a2\n",
    "            # Keep points within the region (with some margin)\n",
    "            if (-0.1 <= point[0] <= region_size + 0.1 and \n",
    "                -0.1 <= point[1] <= region_size + 0.1):\n",
    "                points.append(point)\n",
    "    \n",
    "    return np.array(points)\n",
    "\n",
    "@tf.function\n",
    "def hole_based_renderer(lattice_params, image_size=64):\n",
    "    \"\"\"\n",
    "    Render an image with holes at lattice points (numerically stable version)\n",
    "    \n",
    "    Args:\n",
    "        lattice_params: tensor of shape (batch_size, num_lattices * 5)\n",
    "                       where each lattice has (theta, spacing, phase_x, phase_y, hole_radius)\n",
    "        image_size: size of output image\n",
    "    \n",
    "    Returns:\n",
    "        rendered images of shape (batch_size, image_size, image_size, 1)\n",
    "    \"\"\"\n",
    "    batch_size = tf.shape(lattice_params)[0]\n",
    "    num_lattices = tf.shape(lattice_params)[1] // 5\n",
    "    \n",
    "    # Reshape parameters\n",
    "    params = tf.reshape(lattice_params, (batch_size, num_lattices, 5))\n",
    "    \n",
    "    # Create coordinate grid\n",
    "    x = tf.linspace(0., float(image_size), image_size)\n",
    "    y = tf.linspace(0., float(image_size), image_size)\n",
    "    X, Y = tf.meshgrid(x, y)\n",
    "    \n",
    "    # Initialize output - start with white background\n",
    "    images = tf.ones((batch_size, image_size, image_size, 1))\n",
    "    \n",
    "    # Process each lattice\n",
    "    for i in range(num_lattices):\n",
    "        theta = params[:, i, 0]      # rotation angle\n",
    "        spacing = params[:, i, 1]    # lattice spacing\n",
    "        phase_x = params[:, i, 2]    # phase offset in x\n",
    "        phase_y = params[:, i, 3]    # phase offset in y\n",
    "        hole_radius = params[:, i, 4]  # hole radius\n",
    "        \n",
    "        # Skip if spacing is 0 or too small (empty lattice slot)\n",
    "        mask = tf.cast(spacing > 0.1, tf.float32)[:, None, None, None]\n",
    "        \n",
    "        # Clamp spacing to avoid division issues\n",
    "        spacing = tf.maximum(spacing, 0.1)\n",
    "        \n",
    "        # Create lattice pattern using cosine waves\n",
    "        cos_theta = tf.cos(theta)[:, None, None, None]\n",
    "        sin_theta = tf.sin(theta)[:, None, None, None]\n",
    "        spacing_expanded = spacing[:, None, None, None]\n",
    "        \n",
    "        # Rotated coordinates\n",
    "        X_rot = X[None, :, :, None] * cos_theta + Y[None, :, :, None] * sin_theta\n",
    "        Y_rot = -X[None, :, :, None] * sin_theta + Y[None, :, :, None] * cos_theta\n",
    "        \n",
    "        # Create lattice pattern with clamped division\n",
    "        phase_x_expanded = phase_x[:, None, None, None]\n",
    "        phase_y_expanded = phase_y[:, None, None, None]\n",
    "        \n",
    "        # Add small epsilon to avoid division by zero\n",
    "        safe_spacing = tf.maximum(spacing_expanded, 1e-6)\n",
    "        \n",
    "        pattern_x = tf.cos(2 * np.pi * X_rot / safe_spacing + phase_x_expanded)\n",
    "        pattern_y = tf.cos(2 * np.pi * Y_rot / safe_spacing + phase_y_expanded)\n",
    "        \n",
    "        # Combine patterns - high values at lattice points\n",
    "        lattice_indicator = (pattern_x + 1) * (pattern_y + 1) / 4\n",
    "        \n",
    "        # Create holes: dark spots where lattice_indicator is high\n",
    "        # Use tanh instead of sigmoid for better numerical stability\n",
    "        hole_pattern = 1.0 - 0.5 * (tf.nn.tanh(10.0 * (lattice_indicator - 0.9)) + 1.0)\n",
    "        \n",
    "        # Ensure hole_pattern is in valid range\n",
    "        hole_pattern = tf.clip_by_value(hole_pattern, 0.0, 1.0)\n",
    "        \n",
    "        # Apply mask (only for non-zero lattices)\n",
    "        images = images * (1 - mask) + images * hole_pattern * mask\n",
    "    \n",
    "    # Final clipping to ensure valid range\n",
    "    images = tf.clip_by_value(images, 0.0, 1.0)\n",
    "    \n",
    "    # Check for NaN and replace with default value if any\n",
    "    images = tf.where(tf.math.is_nan(images), tf.ones_like(images) * 0.5, images)\n",
    "    \n",
    "    return images\n",
    "\n",
    "# Test the hole-based renderer\n",
    "print(\"Testing hole-based renderer...\")\n",
    "test_params_holes = tf.constant([[\n",
    "    0.0, 8.0, 0.0, 0.0, 2.0,      # Lattice 1: theta=0, spacing=8, no phase, hole_radius=2\n",
    "    np.pi/4, 10.0, 0.0, 0.0, 1.5   # Lattice 2: theta=45¬∞, spacing=10, hole_radius=1.5\n",
    "]], dtype=tf.float32)\n",
    "\n",
    "rendered_holes = hole_based_renderer(test_params_holes, image_size=64)\n",
    "\n",
    "# Debug information\n",
    "print(f\"Rendered image shape: {rendered_holes.shape}\")\n",
    "print(f\"Rendered image range: [{tf.reduce_min(rendered_holes):.3f}, {tf.reduce_max(rendered_holes):.3f}]\")\n",
    "print(f\"Rendered image mean: {tf.reduce_mean(rendered_holes):.3f}\")\n",
    "print(f\"Number of NaN values: {tf.reduce_sum(tf.cast(tf.math.is_nan(rendered_holes), tf.int32))}\")\n",
    "\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.imshow(rendered_holes[0, :, :, 0], cmap='gray', vmin=0, vmax=1)\n",
    "plt.title('Hole-based Renderer Output')\n",
    "plt.colorbar()\n",
    "\n",
    "# Compare with original continuous renderer for reference\n",
    "test_params_continuous = tf.constant([[0.0, 1.0, 0.0, 0.5,  # Convert to old format\n",
    "                                     np.pi/4, 0.8, 0.0, 0.3]])\n",
    "rendered_continuous = differentiable_renderer(test_params_continuous, image_size=64)\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.imshow(rendered_continuous[0, :, :, 0], cmap='gray')\n",
    "plt.title('Original Continuous Renderer')\n",
    "plt.colorbar()\n",
    "\n",
    "# Create a simple test pattern to verify renderer works\n",
    "simple_test = tf.constant([[0.0, 16.0, 0.0, 0.0, 4.0,  # Simple grid\n",
    "                           0.0, 0.0, 0.0, 0.0, 0.0]], dtype=tf.float32)  # Empty lattice\n",
    "simple_rendered = hole_based_renderer(simple_test, image_size=64)\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.imshow(simple_rendered[0, :, :, 0], cmap='gray', vmin=0, vmax=1)\n",
    "plt.title('Simple Test Pattern')\n",
    "plt.colorbar()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Hole-based renderer output range: [{tf.reduce_min(rendered_holes):.3f}, {tf.reduce_max(rendered_holes):.3f}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd23c572",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 5. Data Loading and Model Training Infrastructure\n",
    "\n",
    "class MoireDataLoader:\n",
    "    \"\"\"Data loader for moir√© lattice training data\"\"\"\n",
    "    \n",
    "    def __init__(self, hdf5_path):\n",
    "        self.hdf5_path = hdf5_path\n",
    "        self.file = None\n",
    "        self._load_metadata()\n",
    "    \n",
    "    def _load_metadata(self):\n",
    "        \"\"\"Load dataset metadata\"\"\"\n",
    "        with h5py.File(self.hdf5_path, 'r') as f:\n",
    "            self.image_size = f.attrs['image_size']\n",
    "            self.max_lattices = f.attrs['max_lattices']\n",
    "            self.num_samples = f.attrs['num_samples']\n",
    "            self.parameter_format = f.attrs['parameter_format']\n",
    "            print(f\"Dataset: {self.num_samples} samples, {self.image_size}x{self.image_size}, max {self.max_lattices} lattices\")\n",
    "    \n",
    "    def create_tf_dataset(self, batch_size=32, shuffle=True, validation_split=0.2):\n",
    "        \"\"\"Create TensorFlow datasets for training and validation\"\"\"\n",
    "        \n",
    "        def data_generator():\n",
    "            with h5py.File(self.hdf5_path, 'r') as f:\n",
    "                indices = np.arange(self.num_samples)\n",
    "                if shuffle:\n",
    "                    np.random.shuffle(indices)\n",
    "                \n",
    "                for idx in indices:\n",
    "                    image = f['images'][idx]\n",
    "                    params = f['parameters'][idx]\n",
    "                    yield image, params\n",
    "        \n",
    "        # Create dataset\n",
    "        dataset = tf.data.Dataset.from_generator(\n",
    "            data_generator,\n",
    "            output_signature=(\n",
    "                tf.TensorSpec(shape=(self.image_size, self.image_size, 1), dtype=tf.float32),\n",
    "                tf.TensorSpec(shape=(self.max_lattices * 5,), dtype=tf.float32)\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        # Split into train/validation\n",
    "        val_size = int(self.num_samples * validation_split)\n",
    "        train_size = self.num_samples - val_size\n",
    "        \n",
    "        train_dataset = dataset.take(train_size).batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
    "        val_dataset = dataset.skip(train_size).batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
    "        \n",
    "        return train_dataset, val_dataset\n",
    "\n",
    "def create_improved_lattice_cnn(input_shape=(64, 64, 1), max_lattices=8, param_per_lattice=5):\n",
    "    \"\"\"\n",
    "    Create an improved CNN for image-to-lattice parameter regression\n",
    "    \n",
    "    Args:\n",
    "        input_shape: input image shape\n",
    "        max_lattices: maximum number of lattices to predict\n",
    "        param_per_lattice: parameters per lattice (theta, spacing, phase_x, phase_y, hole_radius)\n",
    "    \"\"\"\n",
    "    inputs = tf.keras.Input(shape=input_shape)\n",
    "    \n",
    "    # CNN Encoder with residual connections\n",
    "    x = tf.keras.layers.Conv2D(32, (3, 3), activation='relu', padding='same')(inputs)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
    "    x1 = tf.keras.layers.MaxPooling2D((2, 2))(x)  # 32x32\n",
    "    \n",
    "    x = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same')(x1)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "    x2 = tf.keras.layers.MaxPooling2D((2, 2))(x)  # 16x16\n",
    "    \n",
    "    x = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', padding='same')(x2)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n",
    "    x3 = tf.keras.layers.MaxPooling2D((2, 2))(x)  # 8x8\n",
    "    \n",
    "    x = tf.keras.layers.Conv2D(256, (3, 3), activation='relu', padding='same')(x3)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Conv2D(256, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "    \n",
    "    # Dense layers with attention-like mechanism\n",
    "    x = tf.keras.layers.Dense(512, activation='relu')(x)\n",
    "    x = tf.keras.layers.Dropout(0.5)(x)\n",
    "    x = tf.keras.layers.Dense(256, activation='relu')(x)\n",
    "    x = tf.keras.layers.Dropout(0.3)(x)\n",
    "    \n",
    "    # Lattice-specific heads (one for each lattice)\n",
    "    lattice_outputs = []\n",
    "    for i in range(max_lattices):\n",
    "        # Each lattice gets its own small MLP\n",
    "        lattice_features = tf.keras.layers.Dense(64, activation='relu', name=f'lattice_{i}_features')(x)\n",
    "        lattice_params = tf.keras.layers.Dense(param_per_lattice, activation='linear', \n",
    "                                             name=f'lattice_{i}_params')(lattice_features)\n",
    "        lattice_outputs.append(lattice_params)\n",
    "    \n",
    "    # Concatenate all lattice parameters\n",
    "    outputs = tf.keras.layers.Concatenate()(lattice_outputs)\n",
    "    \n",
    "    model = tf.keras.Model(inputs, outputs)\n",
    "    return model\n",
    "\n",
    "# Custom loss function that handles variable number of lattices\n",
    "def moire_reconstruction_loss(y_true, y_pred, image_size=64, alpha=1.0, beta=0.1):\n",
    "    \"\"\"\n",
    "    Custom loss combining parameter MSE and reconstruction error\n",
    "    \n",
    "    Args:\n",
    "        y_true: true parameters (batch_size, max_lattices * 5)\n",
    "        y_pred: predicted parameters (batch_size, max_lattices * 5)\n",
    "        alpha: weight for reconstruction loss\n",
    "        beta: weight for parameter regularization\n",
    "    \"\"\"\n",
    "    # Parameter MSE loss\n",
    "    param_loss = tf.reduce_mean(tf.square(y_true - y_pred))\n",
    "    \n",
    "    # Reconstruction loss (render images and compare)\n",
    "    # Note: This makes training slower but more accurate\n",
    "    pred_images = hole_based_renderer(y_pred, image_size=image_size)\n",
    "    true_images = hole_based_renderer(y_true, image_size=image_size)\n",
    "    reconstruction_loss = tf.reduce_mean(tf.square(pred_images - true_images))\n",
    "    \n",
    "    # Regularization: encourage sparse lattices (many zero parameters)\n",
    "    regularization_loss = tf.reduce_mean(tf.abs(y_pred))\n",
    "    \n",
    "    return param_loss + alpha * reconstruction_loss + beta * regularization_loss\n",
    "\n",
    "# Create the improved model\n",
    "improved_model = create_improved_lattice_cnn(max_lattices=8)\n",
    "\n",
    "# Custom optimizer with learning rate scheduling\n",
    "initial_learning_rate = 0.001\n",
    "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate,\n",
    "    decay_steps=1000,\n",
    "    decay_rate=0.96,\n",
    "    staircase=True\n",
    ")\n",
    "\n",
    "improved_model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=lr_schedule),\n",
    "    loss=lambda y_true, y_pred: moire_reconstruction_loss(y_true, y_pred, image_size=64),\n",
    "    metrics=['mae']\n",
    ")\n",
    "\n",
    "improved_model.summary()\n",
    "\n",
    "print(\"\\nImproved model created with:\")\n",
    "print(\"- Residual connections and batch normalization\")\n",
    "print(\"- Lattice-specific output heads\")\n",
    "print(\"- Custom reconstruction loss\")\n",
    "print(\"- Learning rate scheduling\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62135642",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 6. Training Pipeline and Evaluation\n",
    "\n",
    "def train_moire_model(model, train_dataset, val_dataset, epochs=50, save_path='best_moire_model.h5'):\n",
    "    \"\"\"Train the moir√© lattice reconstruction model\"\"\"\n",
    "    \n",
    "    # Callbacks\n",
    "    callbacks = [\n",
    "        tf.keras.callbacks.ModelCheckpoint(\n",
    "            save_path, \n",
    "            save_best_only=True, \n",
    "            monitor='val_loss',\n",
    "            verbose=1\n",
    "        ),\n",
    "        tf.keras.callbacks.ReduceLROnPlateau(\n",
    "            monitor='val_loss',\n",
    "            factor=0.5,\n",
    "            patience=5,\n",
    "            min_lr=1e-6,\n",
    "            verbose=1\n",
    "        ),\n",
    "        tf.keras.callbacks.EarlyStopping(\n",
    "            monitor='val_loss',\n",
    "            patience=10,\n",
    "            restore_best_weights=True,\n",
    "            verbose=1\n",
    "        )\n",
    "    ]\n",
    "    \n",
    "    # Train model\n",
    "    history = model.fit(\n",
    "        train_dataset,\n",
    "        validation_data=val_dataset,\n",
    "        epochs=epochs,\n",
    "        callbacks=callbacks,\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    return history\n",
    "\n",
    "def evaluate_reconstruction(model, test_images, test_params, num_samples=5):\n",
    "    \"\"\"Evaluate model reconstruction quality\"\"\"\n",
    "    \n",
    "    # Predict parameters\n",
    "    pred_params = model.predict(test_images[:num_samples])\n",
    "    \n",
    "    # Render images from predicted and true parameters\n",
    "    pred_images = hole_based_renderer(pred_params, image_size=test_images.shape[1])\n",
    "    true_images = hole_based_renderer(test_params[:num_samples], image_size=test_images.shape[1])\n",
    "    \n",
    "    # Calculate metrics\n",
    "    mse_reconstruction = tf.reduce_mean(tf.square(pred_images - test_images[:num_samples]))\n",
    "    mse_parameters = tf.reduce_mean(tf.square(pred_params - test_params[:num_samples]))\n",
    "    \n",
    "    # Visualize results\n",
    "    fig, axes = plt.subplots(num_samples, 4, figsize=(16, 4*num_samples))\n",
    "    if num_samples == 1:\n",
    "        axes = axes.reshape(1, -1)\n",
    "    \n",
    "    for i in range(num_samples):\n",
    "        # Original image\n",
    "        axes[i, 0].imshow(test_images[i, :, :, 0], cmap='gray')\n",
    "        axes[i, 0].set_title(f'Original Image {i+1}')\n",
    "        axes[i, 0].axis('off')\n",
    "        \n",
    "        # Predicted reconstruction\n",
    "        axes[i, 1].imshow(pred_images[i, :, :, 0], cmap='gray')\n",
    "        axes[i, 1].set_title(f'Predicted Reconstruction')\n",
    "        axes[i, 1].axis('off')\n",
    "        \n",
    "        # True reconstruction (from true parameters)\n",
    "        axes[i, 2].imshow(true_images[i, :, :, 0], cmap='gray')\n",
    "        axes[i, 2].set_title(f'True Reconstruction')\n",
    "        axes[i, 2].axis('off')\n",
    "        \n",
    "        # Difference\n",
    "        diff = np.abs(pred_images[i, :, :, 0] - test_images[i, :, :, 0])\n",
    "        axes[i, 3].imshow(diff, cmap='hot')\n",
    "        axes[i, 3].set_title(f'Abs Difference')\n",
    "        axes[i, 3].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"Reconstruction MSE: {mse_reconstruction:.6f}\")\n",
    "    print(f\"Parameter MSE: {mse_parameters:.6f}\")\n",
    "    \n",
    "    return mse_reconstruction, mse_parameters\n",
    "\n",
    "## 7. FFT Baseline Implementation\n",
    "\n",
    "def fft_peak_extraction(image, num_peaks=8, min_distance=3):\n",
    "    \"\"\"\n",
    "    Extract peaks from 2D FFT for lattice parameter estimation\n",
    "    \n",
    "    Args:\n",
    "        image: input grayscale image\n",
    "        num_peaks: maximum number of peaks to extract\n",
    "        min_distance: minimum distance between peaks\n",
    "    \n",
    "    Returns:\n",
    "        peak_params: array of lattice parameters (theta, |k|, phi, amplitude)\n",
    "    \"\"\"\n",
    "    # Compute 2D FFT\n",
    "    fft_result = np.fft.fft2(image)\n",
    "    fft_shifted = np.fft.fftshift(fft_result)\n",
    "    magnitude = np.abs(fft_shifted)\n",
    "    phase = np.angle(fft_shifted)\n",
    "    \n",
    "    # Find peaks in magnitude spectrum (exclude DC component)\n",
    "    center = magnitude.shape[0] // 2\n",
    "    magnitude_copy = magnitude.copy()\n",
    "    magnitude_copy[center-2:center+3, center-2:center+3] = 0  # Remove DC and nearby\n",
    "    \n",
    "    # Simple peak detection using local maxima\n",
    "    from scipy.ndimage import maximum_filter\n",
    "    \n",
    "    # Apply maximum filter to find local maxima\n",
    "    neighborhood_size = max(3, min_distance)\n",
    "    local_maxima = maximum_filter(magnitude_copy, size=neighborhood_size)\n",
    "    \n",
    "    # Find positions where original equals local maximum (these are peaks)\n",
    "    peak_mask = (magnitude_copy == local_maxima) & (magnitude_copy > np.max(magnitude_copy) * 0.1)\n",
    "    peak_coords = np.where(peak_mask)\n",
    "    \n",
    "    if len(peak_coords[0]) == 0:\n",
    "        # Fallback: find top values manually\n",
    "        flat_indices = np.argsort(magnitude_copy.flatten())[::-1]\n",
    "        coords = np.unravel_index(flat_indices[:num_peaks*2], magnitude_copy.shape)\n",
    "        peak_coords = (coords[0], coords[1])\n",
    "    \n",
    "    # Get peak coordinates as (y, x) pairs\n",
    "    peaks = list(zip(peak_coords[0], peak_coords[1]))\n",
    "    \n",
    "    # Sort by magnitude and take top peaks\n",
    "    peak_magnitudes = [magnitude_copy[y, x] for y, x in peaks]\n",
    "    sorted_peaks = sorted(zip(peaks, peak_magnitudes), key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    # Extract top peaks\n",
    "    top_peaks = [peak[0] for peak in sorted_peaks[:num_peaks]]\n",
    "    \n",
    "    lattice_params = []\n",
    "    for peak in top_peaks:\n",
    "        y, x = peak\n",
    "        # Convert to k-space coordinates (relative to center)\n",
    "        ky = (y - center) * 2 * np.pi / image.shape[0]\n",
    "        kx = (x - center) * 2 * np.pi / image.shape[1]\n",
    "        \n",
    "        # Calculate parameters\n",
    "        k_magnitude = np.sqrt(kx**2 + ky**2)\n",
    "        if k_magnitude > 0:\n",
    "            theta = np.arctan2(ky, kx)\n",
    "            amplitude = magnitude[y, x] / np.max(magnitude)\n",
    "            phi = phase[y, x]\n",
    "            \n",
    "            lattice_params.append([theta, k_magnitude, phi, amplitude])\n",
    "    \n",
    "    return np.array(lattice_params)\n",
    "\n",
    "def fft_baseline_reconstruction(image, num_lattices=8):\n",
    "    \"\"\"\n",
    "    Baseline FFT-based reconstruction method\n",
    "    \"\"\"\n",
    "    # Debug: print image stats\n",
    "    print(f\"Input image stats: min={np.min(image):.3f}, max={np.max(image):.3f}, mean={np.mean(image):.3f}\")\n",
    "    \n",
    "    # Extract FFT peaks\n",
    "    fft_params = fft_peak_extraction(image, num_peaks=num_lattices)\n",
    "    \n",
    "    if len(fft_params) == 0:\n",
    "        print(\"Warning: No FFT peaks found, returning zeros\")\n",
    "        return np.zeros((num_lattices, 5))\n",
    "    \n",
    "    # Debug: print FFT analysis\n",
    "    fft_result = np.fft.fft2(image)\n",
    "    fft_magnitude = np.abs(np.fft.fftshift(fft_result))\n",
    "    print(f\"FFT magnitude range: [{np.min(fft_magnitude):.1f}, {np.max(fft_magnitude):.1f}]\")\n",
    "    print(f\"Number of FFT peaks found: {len(fft_params)}\")\n",
    "    \n",
    "    # Convert to our parameter format (theta, spacing, phase_x, phase_y, hole_radius)\n",
    "    converted_params = []\n",
    "    for i, params in enumerate(fft_params):\n",
    "        theta, k_mag, phi, amplitude = params\n",
    "        if k_mag > 0 and not np.isnan(k_mag) and not np.isnan(theta):\n",
    "            spacing = 2 * np.pi / k_mag\n",
    "            # Clamp spacing to reasonable range\n",
    "            spacing = np.clip(spacing, 4.0, 32.0)\n",
    "            \n",
    "            # Estimate hole radius from amplitude, make it reasonable\n",
    "            hole_radius = np.clip(amplitude * spacing * 0.15, 0.5, spacing / 4)\n",
    "            \n",
    "            # Normalize phase to [0, 2œÄ]\n",
    "            phase_x = (phi + np.pi) % (2 * np.pi)\n",
    "            phase_y = 0.0  # Set phase_y to 0 for simplicity\n",
    "            \n",
    "            converted_params.append([theta, spacing, phase_x, phase_y, hole_radius])\n",
    "            print(f\"  Peak {i}: k_mag={k_mag:.3f} ‚Üí spacing={spacing:.1f}, amp={amplitude:.3f} ‚Üí radius={hole_radius:.2f}\")\n",
    "    \n",
    "    # If no valid params found, create some default ones\n",
    "    if len(converted_params) == 0:\n",
    "        print(\"Warning: No valid FFT parameters, using defaults\")\n",
    "        converted_params = [[0, 8.0, 0, 0, 1.0]]  # Default lattice\n",
    "    \n",
    "    # Pad to max_lattices with zeros\n",
    "    while len(converted_params) < num_lattices:\n",
    "        converted_params.append([0, 0, 0, 0, 0])  # Zero params = no contribution\n",
    "    \n",
    "    return np.array(converted_params[:num_lattices])\n",
    "\n",
    "# Test FFT baseline with better debugging\n",
    "print(\"Testing FFT baseline with improved debugging...\")\n",
    "test_image_2d = test_image  # Use the test image from earlier\n",
    "\n",
    "# Ensure image is properly normalized\n",
    "if np.max(test_image_2d) > 1.0:\n",
    "    test_image_2d = test_image_2d / np.max(test_image_2d)\n",
    "\n",
    "fft_baseline_params = fft_baseline_reconstruction(test_image_2d, num_lattices=8)\n",
    "\n",
    "print(\"\\nFFT extracted parameters (after conversion):\")\n",
    "for i, params in enumerate(fft_baseline_params):\n",
    "    if params[1] > 0:  # Only show non-zero lattices\n",
    "        print(f\"  Lattice {i}: Œ∏={params[0]:.2f}, spacing={params[1]:.1f}, \"\n",
    "              f\"phases=({params[2]:.2f},{params[3]:.2f}), radius={params[4]:.2f}\")\n",
    "\n",
    "# Render FFT baseline reconstruction\n",
    "fft_params_tf = tf.constant([fft_baseline_params.flatten()], dtype=tf.float32)\n",
    "print(f\"\\nFFT params tensor shape: {fft_params_tf.shape}\")\n",
    "print(f\"FFT params tensor: contains NaN? {tf.reduce_any(tf.math.is_nan(fft_params_tf))}\")\n",
    "\n",
    "fft_reconstruction = hole_based_renderer(fft_params_tf, image_size=64)\n",
    "print(f\"FFT reconstruction shape: {fft_reconstruction.shape}\")\n",
    "print(f\"FFT reconstruction range: [{tf.reduce_min(fft_reconstruction):.3f}, {tf.reduce_max(fft_reconstruction):.3f}]\")\n",
    "print(f\"FFT reconstruction contains NaN? {tf.reduce_any(tf.math.is_nan(fft_reconstruction))}\")\n",
    "\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.imshow(test_image_2d, cmap='gray', vmin=0, vmax=1)\n",
    "plt.title('Original Test Image')\n",
    "plt.colorbar()\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "rendered_image = fft_reconstruction[0, :, :, 0].numpy()\n",
    "if np.any(np.isnan(rendered_image)):\n",
    "    print(\"Warning: Rendered image contains NaN values!\")\n",
    "    rendered_image = np.nan_to_num(rendered_image, nan=0.5)\n",
    "plt.imshow(rendered_image, cmap='gray', vmin=0, vmax=1)\n",
    "plt.title('FFT Baseline Reconstruction')\n",
    "plt.colorbar()\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "error_image = np.abs(test_image_2d - rendered_image)\n",
    "plt.imshow(error_image, cmap='hot', vmin=0, vmax=1)\n",
    "plt.title('Reconstruction Error')\n",
    "plt.colorbar()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Calculate MSE, handling NaN values\n",
    "if np.any(np.isnan(rendered_image)):\n",
    "    fft_mse = np.nan\n",
    "else:\n",
    "    fft_mse = np.mean((test_image_2d - rendered_image)**2)\n",
    "print(f\"\\nFFT Baseline MSE: {fft_mse:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fccccc55",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 8. Complete ML Pipeline Execution\n",
    "\n",
    "# This cell provides the complete workflow to train and evaluate the model\n",
    "# Uncomment and run sections as needed\n",
    "\n",
    "def run_complete_pipeline():\n",
    "    \"\"\"\n",
    "    Complete pipeline for moir√© lattice reconstruction\n",
    "    \"\"\"\n",
    "    print(\"üîß Starting Complete Moir√© Lattice ML Pipeline\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Step 1: Generate training data\n",
    "    print(\"\\nüìä Step 1: Generating training dataset...\")\n",
    "    dataset_path = 'moire_training_data.h5'\n",
    "    \n",
    "    # Create training dataset (adjust num_samples based on your needs)\n",
    "    # Start small for testing, then increase for full training\n",
    "    create_training_dataset(\n",
    "        num_samples=1000,  # Start with 1000 for testing\n",
    "        image_size=64,\n",
    "        max_lattices=8,\n",
    "        save_path=dataset_path,\n",
    "        batch_size=50\n",
    "    )\n",
    "    \n",
    "    # Step 2: Load data\n",
    "    print(\"\\nüìÇ Step 2: Loading data...\")\n",
    "    data_loader = MoireDataLoader(dataset_path)\n",
    "    train_dataset, val_dataset = data_loader.create_tf_dataset(batch_size=16, validation_split=0.2)\n",
    "    \n",
    "    # Step 3: Train model\n",
    "    print(\"\\nüß† Step 3: Training model...\")\n",
    "    model_path = 'best_moire_model.h5'\n",
    "    \n",
    "    # Train for a few epochs first to test\n",
    "    history = train_moire_model(\n",
    "        improved_model, \n",
    "        train_dataset, \n",
    "        val_dataset, \n",
    "        epochs=5,  # Start with 5 epochs for testing\n",
    "        save_path=model_path\n",
    "    )\n",
    "    \n",
    "    # Step 4: Evaluate model\n",
    "    print(\"\\nüìà Step 4: Evaluating model...\")\n",
    "    \n",
    "    # Get test samples\n",
    "    test_batch = next(iter(val_dataset))\n",
    "    test_images, test_params = test_batch\n",
    "    \n",
    "    # Evaluate reconstruction quality\n",
    "    mse_recon, mse_params = evaluate_reconstruction(\n",
    "        improved_model, \n",
    "        test_images, \n",
    "        test_params, \n",
    "        num_samples=3\n",
    "    )\n",
    "    \n",
    "    # Compare with FFT baseline\n",
    "    print(\"\\nüîç Step 5: Comparing with FFT baseline...\")\n",
    "    fft_errors = []\n",
    "    for i in range(min(3, len(test_images))):\n",
    "        fft_params = fft_baseline_reconstruction(test_images[i, :, :, 0].numpy())\n",
    "        fft_params_tf = tf.constant([fft_params.flatten()], dtype=tf.float32)\n",
    "        fft_recon = hole_based_renderer(fft_params_tf, image_size=64)\n",
    "        \n",
    "        # Check for NaN values\n",
    "        if tf.reduce_any(tf.math.is_nan(fft_recon)):\n",
    "            print(f\"Warning: FFT reconstruction {i} contains NaN values\")\n",
    "            fft_error = np.nan\n",
    "        else:\n",
    "            fft_error = tf.reduce_mean(tf.square(fft_recon - test_images[i:i+1]))\n",
    "            fft_errors.append(fft_error.numpy())\n",
    "    \n",
    "    # Filter out NaN values for averaging\n",
    "    valid_fft_errors = [e for e in fft_errors if not np.isnan(e)]\n",
    "    avg_fft_error = np.mean(valid_fft_errors) if valid_fft_errors else np.nan\n",
    "    \n",
    "    print(f\"\\nResults Summary:\")\n",
    "    print(f\"CNN Model - Reconstruction MSE: {mse_recon:.6f}\")\n",
    "    print(f\"CNN Model - Parameter MSE: {mse_params:.6f}\")\n",
    "    print(f\"FFT Baseline - Average MSE: {avg_fft_error:.6f}\")\n",
    "    print(f\"FFT Baseline - Valid samples: {len(valid_fft_errors)}/{len(fft_errors)}\")\n",
    "    \n",
    "    return history, improved_model, data_loader\n",
    "\n",
    "# Instructions for running the pipeline\n",
    "print(\"üìã COMPLETE MOIRE LATTICE ML PIPELINE\")\n",
    "print(\"=\" * 50)\n",
    "print()\n",
    "print(\"To run the complete pipeline, execute:\")\n",
    "print(\"    history, model, loader = run_complete_pipeline()\")\n",
    "print()\n",
    "print(\"Pipeline includes:\")\n",
    "print(\"‚úÖ 1. Training data generation (1000 samples)\")\n",
    "print(\"‚úÖ 2. Data loading and preprocessing\")\n",
    "print(\"‚úÖ 3. Model training (5 epochs for testing)\")\n",
    "print(\"‚úÖ 4. Model evaluation and visualization\")\n",
    "print(\"‚úÖ 5. FFT baseline comparison\")\n",
    "print()\n",
    "print(\"For production training:\")\n",
    "print(\"‚Ä¢ Increase num_samples to 10000+ in create_training_dataset()\")\n",
    "print(\"‚Ä¢ Increase epochs to 50+ in train_moire_model()\")\n",
    "print(\"‚Ä¢ Monitor training on validation set\")\n",
    "print()\n",
    "print(\"Next steps after testing:\")\n",
    "print(\"üî¨ 1. Test on real grayscale images\")\n",
    "print(\"üîß 2. Fine-tune hyperparameters\")\n",
    "print(\"üìä 3. Add more evaluation metrics\")\n",
    "print(\"üöÄ 4. Deploy for inference\")\n",
    "\n",
    "# Create a smaller test run function for quick testing\n",
    "def quick_test_pipeline():\n",
    "    \"\"\"Quick test with minimal data for debugging\"\"\"\n",
    "    print(\"üß™ Quick Test Pipeline (100 samples, 2 epochs)\")\n",
    "    \n",
    "    # Generate minimal test data\n",
    "    create_training_dataset(num_samples=100, image_size=64, max_lattices=4, \n",
    "                          save_path='test_data.h5', batch_size=20)\n",
    "    \n",
    "    # Load and train\n",
    "    loader = MoireDataLoader('test_data.h5')\n",
    "    train_ds, val_ds = loader.create_tf_dataset(batch_size=8, validation_split=0.3)\n",
    "    \n",
    "    # Quick training\n",
    "    test_model = create_improved_lattice_cnn(max_lattices=4)\n",
    "    test_model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "    \n",
    "    history = test_model.fit(train_ds, validation_data=val_ds, epochs=2, verbose=1)\n",
    "    \n",
    "    print(\"‚úÖ Quick test completed successfully!\")\n",
    "    return test_model, loader\n",
    "\n",
    "print(\"\\nFor quick testing, run: quick_test_pipeline()\")\n",
    "quick_test_pipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dd86d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 4. Training Data Generation Pipeline\n",
    "\n",
    "def generate_random_lattice_params(num_lattices_range=(2, 8), image_size=64):\n",
    "    \"\"\"\n",
    "    Generate random lattice parameters for training data\n",
    "    \n",
    "    Returns:\n",
    "        lattice_params: array of shape (num_lattices, 5) with parameters\n",
    "                       (theta, spacing, phase_x, phase_y, hole_radius)\n",
    "    \"\"\"\n",
    "    num_lattices = np.random.randint(num_lattices_range[0], num_lattices_range[1] + 1)\n",
    "    \n",
    "    params = []\n",
    "    for _ in range(num_lattices):\n",
    "        # Rotation angle [0, 2œÄ)\n",
    "        theta = np.random.uniform(0, 2 * np.pi)\n",
    "        \n",
    "        # Lattice spacing [4, image_size/2] to ensure visible patterns\n",
    "        spacing = np.random.uniform(4, image_size // 2)\n",
    "        \n",
    "        # Phase offsets [0, 2œÄ)\n",
    "        phase_x = np.random.uniform(0, 2 * np.pi)\n",
    "        phase_y = np.random.uniform(0, 2 * np.pi)\n",
    "        \n",
    "        # Hole radius [0.5, spacing/3] to ensure holes don't overlap too much\n",
    "        hole_radius = np.random.uniform(0.5, min(spacing / 3, 4.0))\n",
    "        \n",
    "        params.append([theta, spacing, phase_x, phase_y, hole_radius])\n",
    "    \n",
    "    # Pad with zeros if needed to reach maximum number of lattices\n",
    "    max_lattices = num_lattices_range[1]\n",
    "    while len(params) < max_lattices:\n",
    "        params.append([0, 0, 0, 0, 0])  # Zero params = no contribution\n",
    "    \n",
    "    return np.array(params)\n",
    "\n",
    "def create_training_dataset(num_samples=10000, image_size=64, max_lattices=8, \n",
    "                          save_path='moire_training_data.h5', batch_size=100):\n",
    "    \"\"\"\n",
    "    Create a large training dataset and save to HDF5 file\n",
    "    \n",
    "    Args:\n",
    "        num_samples: number of training examples\n",
    "        image_size: size of generated images\n",
    "        max_lattices: maximum number of lattices per image\n",
    "        save_path: path to save HDF5 file\n",
    "        batch_size: batch size for generation (to manage memory)\n",
    "    \"\"\"\n",
    "    print(f\"Creating training dataset with {num_samples} samples...\")\n",
    "    print(f\"Image size: {image_size}x{image_size}, Max lattices: {max_lattices}\")\n",
    "    \n",
    "    # Create HDF5 file\n",
    "    with h5py.File(save_path, 'w') as f:\n",
    "        # Create datasets\n",
    "        images_ds = f.create_dataset('images', (num_samples, image_size, image_size, 1), \n",
    "                                   dtype=np.float32, compression='gzip')\n",
    "        params_ds = f.create_dataset('parameters', (num_samples, max_lattices * 5), \n",
    "                                   dtype=np.float32, compression='gzip')\n",
    "        num_lattices_ds = f.create_dataset('num_lattices', (num_samples,), \n",
    "                                         dtype=np.int32, compression='gzip')\n",
    "        \n",
    "        # Add metadata\n",
    "        f.attrs['image_size'] = image_size\n",
    "        f.attrs['max_lattices'] = max_lattices\n",
    "        f.attrs['num_samples'] = num_samples\n",
    "        f.attrs['created_date'] = datetime.now().isoformat()\n",
    "        f.attrs['parameter_format'] = 'theta, spacing, phase_x, phase_y, hole_radius'\n",
    "        \n",
    "        # Generate data in batches\n",
    "        for batch_start in range(0, num_samples, batch_size):\n",
    "            batch_end = min(batch_start + batch_size, num_samples)\n",
    "            current_batch_size = batch_end - batch_start\n",
    "            \n",
    "            print(f\"Generating batch {batch_start//batch_size + 1}/{(num_samples-1)//batch_size + 1}...\")\n",
    "            \n",
    "            batch_images = []\n",
    "            batch_params = []\n",
    "            batch_num_lattices = []\n",
    "            \n",
    "            for i in range(current_batch_size):\n",
    "                # Generate random parameters\n",
    "                lattice_params = generate_random_lattice_params((2, max_lattices), image_size)\n",
    "                num_actual_lattices = np.sum(lattice_params[:, 1] > 0)  # Count non-zero spacings\n",
    "                \n",
    "                # Flatten parameters for model input\n",
    "                flat_params = lattice_params.flatten()\n",
    "                \n",
    "                # Render image using TensorFlow (convert to TF format)\n",
    "                tf_params = tf.constant([flat_params], dtype=tf.float32)\n",
    "                rendered = hole_based_renderer(tf_params, image_size=image_size)\n",
    "                image = rendered[0].numpy()\n",
    "                \n",
    "                # Add some noise to make training more robust\n",
    "                noise_level = np.random.uniform(0, 0.05)\n",
    "                image += np.random.normal(0, noise_level, image.shape)\n",
    "                image = np.clip(image, 0, 1)\n",
    "                \n",
    "                batch_images.append(image)\n",
    "                batch_params.append(flat_params)\n",
    "                batch_num_lattices.append(num_actual_lattices)\n",
    "            \n",
    "            # Save batch to HDF5\n",
    "            images_ds[batch_start:batch_end] = np.array(batch_images)\n",
    "            params_ds[batch_start:batch_end] = np.array(batch_params)\n",
    "            num_lattices_ds[batch_start:batch_end] = np.array(batch_num_lattices)\n",
    "    \n",
    "    print(f\"Dataset saved to {save_path}\")\n",
    "    print(f\"File size: {os.path.getsize(save_path) / (1024**2):.1f} MB\")\n",
    "\n",
    "# Test data generation with a small sample\n",
    "print(\"Testing data generation...\")\n",
    "test_params = generate_random_lattice_params((2, 4), image_size=64)\n",
    "print(f\"Generated parameters shape: {test_params.shape}\")\n",
    "print(f\"Sample parameters:\")\n",
    "for i, params in enumerate(test_params):\n",
    "    if params[1] > 0:  # Only show non-zero lattices\n",
    "        print(f\"  Lattice {i}: Œ∏={params[0]:.2f}, spacing={params[1]:.1f}, \"\n",
    "              f\"phases=({params[2]:.2f},{params[3]:.2f}), radius={params[4]:.1f}\")\n",
    "\n",
    "# Render test image\n",
    "tf_test_params = tf.constant([test_params.flatten()], dtype=tf.float32)\n",
    "test_rendered = hole_based_renderer(tf_test_params, image_size=64)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.imshow(test_rendered[0, :, :, 0], cmap='gray')\n",
    "plt.title('Test Generated Training Sample')\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Test image range: [{tf.reduce_min(test_rendered):.3f}, {tf.reduce_max(test_rendered):.3f}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d19fd3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 8.5. Alternative: On-the-Fly Data Generation\n",
    "\n",
    "class OnTheFlyMoireDataGenerator:\n",
    "    \"\"\"\n",
    "    Generate moir√© lattice training data on-the-fly during training\n",
    "    This saves disk space and allows infinite data variation\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, image_size=64, max_lattices=8, num_lattices_range=(2, 6)):\n",
    "        self.image_size = image_size\n",
    "        self.max_lattices = max_lattices\n",
    "        self.num_lattices_range = num_lattices_range\n",
    "    \n",
    "    def generate_batch(self, batch_size):\n",
    "        \"\"\"Generate a batch of training data\"\"\"\n",
    "        batch_images = []\n",
    "        batch_params = []\n",
    "        \n",
    "        for _ in range(batch_size):\n",
    "            # Generate random parameters\n",
    "            lattice_params = generate_random_lattice_params(\n",
    "                self.num_lattices_range, self.image_size\n",
    "            )\n",
    "            flat_params = lattice_params.flatten()\n",
    "            \n",
    "            # Render image\n",
    "            tf_params = tf.constant([flat_params], dtype=tf.float32)\n",
    "            rendered = hole_based_renderer(tf_params, image_size=self.image_size)\n",
    "            image = rendered[0].numpy()\n",
    "            \n",
    "            # Add noise for robustness\n",
    "            noise_level = np.random.uniform(0, 0.05)\n",
    "            image += np.random.normal(0, noise_level, image.shape)\n",
    "            image = np.clip(image, 0, 1)\n",
    "            \n",
    "            batch_images.append(image)\n",
    "            batch_params.append(flat_params)\n",
    "        \n",
    "        return np.array(batch_images), np.array(batch_params)\n",
    "    \n",
    "    def create_tf_dataset(self, batch_size=32, steps_per_epoch=100):\n",
    "        \"\"\"Create TensorFlow dataset with on-the-fly generation\"\"\"\n",
    "        \n",
    "        def data_generator():\n",
    "            while True:  # Infinite generator\n",
    "                images, params = self.generate_batch(batch_size)\n",
    "                for i in range(batch_size):\n",
    "                    yield images[i], params[i]\n",
    "        \n",
    "        dataset = tf.data.Dataset.from_generator(\n",
    "            data_generator,\n",
    "            output_signature=(\n",
    "                tf.TensorSpec(shape=(self.image_size, self.image_size, 1), dtype=tf.float32),\n",
    "                tf.TensorSpec(shape=(self.max_lattices * 5,), dtype=tf.float32)\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        return dataset.batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "def run_onthefly_pipeline():\n",
    "    \"\"\"\n",
    "    Alternative pipeline using on-the-fly data generation\n",
    "    Faster to start, uses less disk space, infinite data variation\n",
    "    \"\"\"\n",
    "    print(\"üöÄ On-the-Fly Moir√© Lattice ML Pipeline\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Create data generator\n",
    "    data_gen = OnTheFlyMoireDataGenerator(image_size=64, max_lattices=8)\n",
    "    \n",
    "    # Create datasets\n",
    "    print(\"üìä Creating on-the-fly datasets...\")\n",
    "    train_dataset = data_gen.create_tf_dataset(batch_size=16, steps_per_epoch=50)\n",
    "    val_dataset = data_gen.create_tf_dataset(batch_size=16, steps_per_epoch=10)\n",
    "    \n",
    "    # Create model\n",
    "    print(\"üß† Creating model...\")\n",
    "    model = create_improved_lattice_cnn(max_lattices=8)\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "        loss='mse',  # Simpler loss for faster training\n",
    "        metrics=['mae']\n",
    "    )\n",
    "    \n",
    "    # Train model\n",
    "    print(\"üéØ Training model...\")\n",
    "    history = model.fit(\n",
    "        train_dataset,\n",
    "        steps_per_epoch=50,  # Number of batches per epoch\n",
    "        validation_data=val_dataset,\n",
    "        validation_steps=10,  # Number of validation batches\n",
    "        epochs=10,\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    # Test model\n",
    "    print(\"üìà Testing model...\")\n",
    "    test_images, test_params = data_gen.generate_batch(3)\n",
    "    \n",
    "    # Predict\n",
    "    pred_params = model.predict(test_images)\n",
    "    \n",
    "    # Visualize results\n",
    "    fig, axes = plt.subplots(3, 3, figsize=(12, 12))\n",
    "    \n",
    "    for i in range(3):\n",
    "        # Original image\n",
    "        axes[i, 0].imshow(test_images[i, :, :, 0], cmap='gray')\n",
    "        axes[i, 0].set_title(f'Original {i+1}')\n",
    "        axes[i, 0].axis('off')\n",
    "        \n",
    "        # Predicted reconstruction\n",
    "        pred_tf = tf.constant([pred_params[i]], dtype=tf.float32)\n",
    "        pred_recon = hole_based_renderer(pred_tf, image_size=64)\n",
    "        axes[i, 1].imshow(pred_recon[0, :, :, 0], cmap='gray')\n",
    "        axes[i, 1].set_title(f'Predicted {i+1}')\n",
    "        axes[i, 1].axis('off')\n",
    "        \n",
    "        # True reconstruction\n",
    "        true_tf = tf.constant([test_params[i]], dtype=tf.float32)\n",
    "        true_recon = hole_based_renderer(true_tf, image_size=64)\n",
    "        axes[i, 2].imshow(true_recon[0, :, :, 0], cmap='gray')\n",
    "        axes[i, 2].set_title(f'True {i+1}')\n",
    "        axes[i, 2].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Calculate MSE\n",
    "    pred_recons = hole_based_renderer(pred_params, image_size=64)\n",
    "    mse = tf.reduce_mean(tf.square(pred_recons - test_images)).numpy()\n",
    "    print(f\"Test MSE: {mse:.6f}\")\n",
    "    \n",
    "    return model, history, data_gen\n",
    "\n",
    "print(\"\\nüí° TWO APPROACHES AVAILABLE:\")\n",
    "print(\"1. Pre-generated Dataset: run_complete_pipeline()\")\n",
    "print(\"   ‚úÖ Consistent data, reproducible results\")\n",
    "print(\"   ‚ùå Requires disk space, limited variation\")\n",
    "print()\n",
    "print(\"2. On-the-Fly Generation: run_onthefly_pipeline()\")\n",
    "print(\"   ‚úÖ No disk space, infinite variation, faster start\")\n",
    "print(\"   ‚ùå Slightly slower training, less reproducible\")\n",
    "print()\n",
    "print(\"For quick testing, recommend: run_onthefly_pipeline()\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19eb71ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final Summary and Status\n",
    "print(\"üéâ MOIR√â LATTICE RECONSTRUCTION ML PIPELINE - READY!\")\n",
    "print(\"=\" * 60)\n",
    "print()\n",
    "print(\"‚úÖ Environment setup complete\")\n",
    "print(\"‚úÖ Hole-based differentiable renderer implemented\")\n",
    "print(\"‚úÖ Training data generation pipeline ready\")\n",
    "print(\"‚úÖ HDF5 storage system configured\")\n",
    "print(\"‚úÖ Improved CNN architecture with residual connections\")\n",
    "print(\"‚úÖ Custom reconstruction loss function\")\n",
    "print(\"‚úÖ Training pipeline with callbacks and monitoring\")\n",
    "print(\"‚úÖ Evaluation metrics and visualization\")\n",
    "print(\"‚úÖ FFT baseline for comparison\")\n",
    "print(\"‚úÖ Complete workflow automation\")\n",
    "print()\n",
    "print(\"üöÄ Ready for moir√© lattice reconstruction research!\")\n",
    "print()\n",
    "print(\"Next: Run the pipeline and analyze results!\")\n",
    "print(\"Execute: history, model, loader = run_complete_pipeline()\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
