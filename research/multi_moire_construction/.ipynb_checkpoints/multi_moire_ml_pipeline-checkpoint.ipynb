{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1172376b",
   "metadata": {},
   "source": [
    "# MoirÃ© Lattice Reconstruction - ML Pipeline\n",
    "\n",
    "This notebook implements a complete ML framework for reconstructing grayscale images as multiple moirÃ© lattices.\n",
    "\n",
    "## Project Overview\n",
    "- **Input**: Grayscale images\n",
    "- **Output**: Array of Bravais lattices with parameters (base vectors, hole size)\n",
    "- **Approach**: Both algorithmic (FFT-based) and learned (CNN) methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ffba25d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-05 01:45:43.206810: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-08-05 01:45:43.215766: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1754358343.226408   12241 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1754358343.229633   12241 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1754358343.237807   12241 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1754358343.237820   12241 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1754358343.237821   12241 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1754358343.237822   12241 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-08-05 01:45:43.240677: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.19.0\n",
      "NumPy version: 2.1.3\n",
      "GPUs available: 1\n",
      "  PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')\n"
     ]
    }
   ],
   "source": [
    "# Environment Setup and Imports\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import fft\n",
    "from scipy.ndimage import maximum_filter\n",
    "import cv2\n",
    "import h5py\n",
    "import os\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "# Configure TensorFlow for better memory management\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        # Restrict TensorFlow to only allocate memory as needed\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    except RuntimeError as e:\n",
    "        print(f\"GPU configuration error: {e}\")\n",
    "\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "print(f\"NumPy version: {np.__version__}\")\n",
    "print(f\"GPUs available: {len(gpus)}\")\n",
    "for gpu in gpus:\n",
    "    print(f\"  {gpu}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d3665a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… CUDA memory management configured\n",
      "Environment variables set:\n",
      "  TF_FORCE_GPU_ALLOW_GROWTH = true\n",
      "  TF_CUDNN_USE_AUTOTUNE = 0\n",
      "  TF_GPU_ALLOCATOR = not set\n"
     ]
    }
   ],
   "source": [
    "# CUDA Memory Management Configuration\n",
    "import os\n",
    "\n",
    "# Disable GPU memory pre-allocation\n",
    "os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'\n",
    "\n",
    "# Disable cuDNN autotune to prevent memory spikes\n",
    "os.environ['TF_CUDNN_USE_AUTOTUNE'] = '0'\n",
    "\n",
    "# Limit TensorFlow to use only necessary GPU memory\n",
    "\n",
    "# Optional: Set CUDA device order\n",
    "os.environ['CUDA_DEVICE_ORDER'] = 'PCI_BUS_ID'\n",
    "\n",
    "# Optional: Limit to specific GPU if multiple are available\n",
    "# os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "\n",
    "print(\"âœ… CUDA memory management configured\")\n",
    "print(\"Environment variables set:\")\n",
    "for key in ['TF_FORCE_GPU_ALLOW_GROWTH', 'TF_CUDNN_USE_AUTOTUNE', 'TF_GPU_ALLOCATOR']:\n",
    "    print(f\"  {key} = {os.environ.get(key, 'not set')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d938f59c",
   "metadata": {},
   "source": [
    "## 1. Differentiable Renderer\n",
    "\n",
    "Implements a hole-based renderer that creates moirÃ© patterns with holes at lattice points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5206dde3",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def hole_based_renderer(lattice_params, image_size=128):\n",
    "    \"\"\"\n",
    "    Render an image with holes at lattice points (numerically stable version)\n",
    "    Updated for 128px default image size\n",
    "    \n",
    "    Args:\n",
    "        lattice_params: tensor of shape (batch_size, num_lattices * 5)\n",
    "                       where each lattice has (theta, spacing, phase_x, phase_y, hole_radius)\n",
    "        image_size: size of output image (default 128 for better pattern visibility)\n",
    "    \n",
    "    Returns:\n",
    "        rendered images of shape (batch_size, image_size, image_size, 1)\n",
    "    \"\"\"\n",
    "    batch_size = tf.shape(lattice_params)[0]\n",
    "    num_lattices = tf.shape(lattice_params)[1] // 5\n",
    "    \n",
    "    # Reshape parameters\n",
    "    params = tf.reshape(lattice_params, (batch_size, num_lattices, 5))\n",
    "    \n",
    "    # Create coordinate grid\n",
    "    x = tf.linspace(0., float(image_size), image_size)\n",
    "    y = tf.linspace(0., float(image_size), image_size)\n",
    "    X, Y = tf.meshgrid(x, y)\n",
    "    \n",
    "    # Initialize output - start with white background\n",
    "    images = tf.ones((batch_size, image_size, image_size, 1))\n",
    "    \n",
    "    # Process each lattice\n",
    "    for i in range(num_lattices):\n",
    "        theta = params[:, i, 0]      # rotation angle\n",
    "        spacing = params[:, i, 1]    # lattice spacing\n",
    "        phase_x = params[:, i, 2]    # phase offset in x\n",
    "        phase_y = params[:, i, 3]    # phase offset in y\n",
    "        hole_radius = params[:, i, 4]  # hole radius\n",
    "        \n",
    "        # Skip if spacing is 0 or too small (empty lattice slot)\n",
    "        # Increased threshold for 128px images\n",
    "        mask = tf.cast(spacing > 0.5, tf.float32)[:, None, None, None]\n",
    "        \n",
    "        # Clamp spacing to avoid division issues\n",
    "        spacing = tf.maximum(spacing, 0.5)\n",
    "        \n",
    "        # Create lattice pattern using cosine waves\n",
    "        cos_theta = tf.cos(theta)[:, None, None, None]\n",
    "        sin_theta = tf.sin(theta)[:, None, None, None]\n",
    "        spacing_expanded = spacing[:, None, None, None]\n",
    "        \n",
    "        # Rotated coordinates\n",
    "        X_rot = X[None, :, :, None] * cos_theta + Y[None, :, :, None] * sin_theta\n",
    "        Y_rot = -X[None, :, :, None] * sin_theta + Y[None, :, :, None] * cos_theta\n",
    "        \n",
    "        # Create lattice pattern with clamped division\n",
    "        phase_x_expanded = phase_x[:, None, None, None]\n",
    "        phase_y_expanded = phase_y[:, None, None, None]\n",
    "        \n",
    "        # Add small epsilon to avoid division by zero\n",
    "        safe_spacing = tf.maximum(spacing_expanded, 1e-6)\n",
    "        \n",
    "        pattern_x = tf.cos(2 * np.pi * X_rot / safe_spacing + phase_x_expanded)\n",
    "        pattern_y = tf.cos(2 * np.pi * Y_rot / safe_spacing + phase_y_expanded)\n",
    "        \n",
    "        # Combine patterns - high values at lattice points\n",
    "        lattice_indicator = (pattern_x + 1) * (pattern_y + 1) / 4\n",
    "        \n",
    "        # Create holes: dark spots where lattice_indicator is high\n",
    "        hole_pattern = 1.0 - 0.5 * (tf.nn.tanh(10.0 * (lattice_indicator - 0.9)) + 1.0)\n",
    "        \n",
    "        # Ensure hole_pattern is in valid range\n",
    "        hole_pattern = tf.clip_by_value(hole_pattern, 0.0, 1.0)\n",
    "        \n",
    "        # Apply mask (only for non-zero lattices)\n",
    "        images = images * (1 - mask) + images * hole_pattern * mask\n",
    "    \n",
    "    # Final clipping to ensure valid range\n",
    "    images = tf.clip_by_value(images, 0.0, 1.0)\n",
    "    \n",
    "    # Check for NaN and replace with default value if any\n",
    "    images = tf.where(tf.math.is_nan(images), tf.ones_like(images) * 0.5, images)\n",
    "    \n",
    "    return images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a4d3afe",
   "metadata": {},
   "source": [
    "## 2. Training Data Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cd50e0e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_random_lattice_params(num_lattices_range=(2, 8), image_size=128):\n",
    "    \"\"\"\n",
    "    Generate random lattice parameters for training data with constraints\n",
    "    to ensure at least 3 lattice points are visible for vector inference\n",
    "    \n",
    "    Returns:\n",
    "        lattice_params: array of shape (num_lattices, 5) with parameters\n",
    "                       (theta, spacing, phase_x, phase_y, hole_radius)\n",
    "    \"\"\"\n",
    "    num_lattices = np.random.randint(num_lattices_range[0], num_lattices_range[1] + 1)\n",
    "    \n",
    "    params = []\n",
    "    for _ in range(num_lattices):\n",
    "        # Rotation angle [0, 2Ï€)\n",
    "        theta = np.random.uniform(0, 2 * np.pi)\n",
    "        \n",
    "        # Lattice spacing: ensure at least 3-4 periods fit in image\n",
    "        # This guarantees we can see enough structure to infer periodicity\n",
    "        min_spacing = image_size // 8   # At least 8 periods\n",
    "        max_spacing = image_size // 3   # At least 3 periods\n",
    "        spacing = np.random.uniform(min_spacing, max_spacing)\n",
    "        \n",
    "        # Phase offsets [0, 2Ï€) - randomize starting position\n",
    "        phase_x = np.random.uniform(0, 2 * np.pi)\n",
    "        phase_y = np.random.uniform(0, 2 * np.pi)\n",
    "        \n",
    "        # Hole radius: proportional to spacing but not too large\n",
    "        # Ensure holes don't merge and destroy periodicity\n",
    "        hole_radius = np.random.uniform(0.8, min(spacing / 4, 6.0))\n",
    "        \n",
    "        params.append([theta, spacing, phase_x, phase_y, hole_radius])\n",
    "    \n",
    "    # Pad with zeros if needed to reach maximum number of lattices\n",
    "    max_lattices = num_lattices_range[1]\n",
    "    while len(params) < max_lattices:\n",
    "        params.append([0, 0, 0, 0, 0])  # Zero params = no contribution\n",
    "    \n",
    "    return np.array(params)\n",
    "\n",
    "def check_existing_dataset(file_path, required_samples, image_size, max_lattices):\n",
    "    \"\"\"\n",
    "    Check if an existing dataset meets our requirements\n",
    "    \n",
    "    Returns:\n",
    "        bool: True if dataset is valid and sufficient\n",
    "    \"\"\"\n",
    "    if not os.path.exists(file_path):\n",
    "        return False\n",
    "    \n",
    "    try:\n",
    "        with h5py.File(file_path, 'r') as f:\n",
    "            # Check if all required datasets exist\n",
    "            required_keys = ['images', 'parameters', 'num_lattices']\n",
    "            if not all(key in f for key in required_keys):\n",
    "                print(f\"Dataset missing required keys. Found: {list(f.keys())}\")\n",
    "                return False\n",
    "            \n",
    "            # Check dimensions\n",
    "            if (f.attrs.get('image_size', 0) != image_size or \n",
    "                f.attrs.get('max_lattices', 0) != max_lattices):\n",
    "                print(f\"Dataset dimensions don't match. \"\n",
    "                      f\"Found: {f.attrs.get('image_size')}x{f.attrs.get('image_size')}, \"\n",
    "                      f\"max_lattices={f.attrs.get('max_lattices')}\")\n",
    "                return False\n",
    "            \n",
    "            # Check if we have enough samples\n",
    "            actual_samples = f['images'].shape[0]\n",
    "            if actual_samples < required_samples:\n",
    "                print(f\"Dataset has {actual_samples} samples, need {required_samples}\")\n",
    "                return False\n",
    "            \n",
    "            print(f\"âœ… Found valid existing dataset with {actual_samples} samples\")\n",
    "            return True\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error checking existing dataset: {e}\")\n",
    "        return False\n",
    "\n",
    "def create_training_dataset(num_samples=10000, image_size=128, max_lattices=8, \n",
    "                          save_path='moire_training_data.h5', batch_size=100):\n",
    "    \"\"\"\n",
    "    Create a large training dataset and save to HDF5 file\n",
    "    Check for existing valid dataset first\n",
    "    \n",
    "    Updated for 128px images and larger dataset size for better coverage\n",
    "    \"\"\"\n",
    "    print(f\"Checking for existing dataset at {save_path}...\")\n",
    "    \n",
    "    # Check if valid dataset already exists\n",
    "    if check_existing_dataset(save_path, num_samples, image_size, max_lattices):\n",
    "        print(\"Using existing dataset!\")\n",
    "        return\n",
    "    \n",
    "    print(f\"Creating new training dataset with {num_samples} samples...\")\n",
    "    print(f\"Image size: {image_size}x{image_size}, Max lattices: {max_lattices}\")\n",
    "    print(f\"Lattice spacing range: {image_size//8} to {image_size//3} pixels\")\n",
    "    \n",
    "    # Remove existing file if it exists but is invalid\n",
    "    if os.path.exists(save_path):\n",
    "        try:\n",
    "            os.remove(save_path)\n",
    "            print(f\"Removed invalid existing file: {save_path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Warning: Could not remove existing file: {e}\")\n",
    "            # Try with a different filename\n",
    "            save_path = save_path.replace('.h5', '_new.h5')\n",
    "            print(f\"Using alternative filename: {save_path}\")\n",
    "    \n",
    "    # Create HDF5 file\n",
    "    try:\n",
    "        with h5py.File(save_path, 'w') as f:\n",
    "            # Create datasets\n",
    "            images_ds = f.create_dataset('images', (num_samples, image_size, image_size, 1), \n",
    "                                       dtype=np.float32, compression='gzip')\n",
    "            params_ds = f.create_dataset('parameters', (num_samples, max_lattices * 5), \n",
    "                                       dtype=np.float32, compression='gzip')\n",
    "            num_lattices_ds = f.create_dataset('num_lattices', (num_samples,), \n",
    "                                             dtype=np.int32, compression='gzip')\n",
    "            \n",
    "            # Add metadata\n",
    "            f.attrs['image_size'] = image_size\n",
    "            f.attrs['max_lattices'] = max_lattices\n",
    "            f.attrs['num_samples'] = num_samples\n",
    "            f.attrs['created_date'] = datetime.now().isoformat()\n",
    "            f.attrs['parameter_format'] = 'theta, spacing, phase_x, phase_y, hole_radius'\n",
    "            f.attrs['spacing_range'] = f'{image_size//8} to {image_size//3} pixels'\n",
    "            \n",
    "            # Generate data in batches\n",
    "            for batch_start in range(0, num_samples, batch_size):\n",
    "                batch_end = min(batch_start + batch_size, num_samples)\n",
    "                current_batch_size = batch_end - batch_start\n",
    "                \n",
    "                print(f\"Generating batch {batch_start//batch_size + 1}/{(num_samples-1)//batch_size + 1}...\")\n",
    "                \n",
    "                batch_images = []\n",
    "                batch_params = []\n",
    "                batch_num_lattices = []\n",
    "                \n",
    "                for i in range(current_batch_size):\n",
    "                    # Generate random parameters with new constraints\n",
    "                    lattice_params = generate_random_lattice_params((2, max_lattices), image_size)\n",
    "                    num_actual_lattices = np.sum(lattice_params[:, 1] > 0)  # Count non-zero spacings\n",
    "                    \n",
    "                    # Flatten parameters for model input\n",
    "                    flat_params = lattice_params.flatten()\n",
    "                    \n",
    "                    # Render image using TensorFlow (convert to TF format)\n",
    "                    tf_params = tf.constant([flat_params], dtype=tf.float32)\n",
    "                    rendered = hole_based_renderer(tf_params, image_size=image_size)\n",
    "                    image = rendered[0].numpy()\n",
    "                    \n",
    "                    # Add some noise to make training more robust\n",
    "                    noise_level = np.random.uniform(0, 0.03)  # Slightly less noise for 128px\n",
    "                    image += np.random.normal(0, noise_level, image.shape)\n",
    "                    image = np.clip(image, 0, 1)\n",
    "                    \n",
    "                    batch_images.append(image)\n",
    "                    batch_params.append(flat_params)\n",
    "                    batch_num_lattices.append(num_actual_lattices)\n",
    "                \n",
    "                # Save batch to HDF5\n",
    "                images_ds[batch_start:batch_end] = np.array(batch_images)\n",
    "                params_ds[batch_start:batch_end] = np.array(batch_params)\n",
    "                num_lattices_ds[batch_start:batch_end] = np.array(batch_num_lattices)\n",
    "                \n",
    "                # Clear TF graph to prevent memory buildup\n",
    "                tf.keras.backend.clear_session()\n",
    "        \n",
    "        print(f\"Dataset saved to {save_path}\")\n",
    "        print(f\"File size: {os.path.getsize(save_path) / (1024**2):.1f} MB\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error creating dataset: {e}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e6cf8f4",
   "metadata": {},
   "source": [
    "## 3. Data Loading Infrastructure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c9814e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MoireDataLoader:\n",
    "    \"\"\"Data loader for moirÃ© lattice training data\"\"\"\n",
    "    \n",
    "    def __init__(self, hdf5_path):\n",
    "        self.hdf5_path = hdf5_path\n",
    "        self.file = None\n",
    "        \n",
    "        # Check if the file exists, if not try alternative naming\n",
    "        if not os.path.exists(hdf5_path):\n",
    "            alt_path = hdf5_path.replace('.h5', '_new.h5')\n",
    "            if os.path.exists(alt_path):\n",
    "                print(f\"Using alternative dataset path: {alt_path}\")\n",
    "                self.hdf5_path = alt_path\n",
    "            else:\n",
    "                raise FileNotFoundError(f\"Dataset not found at {hdf5_path} or {alt_path}\")\n",
    "        \n",
    "        self._load_metadata()\n",
    "    \n",
    "    def _load_metadata(self):\n",
    "        \"\"\"Load dataset metadata\"\"\"\n",
    "        with h5py.File(self.hdf5_path, 'r') as f:\n",
    "            self.image_size = f.attrs['image_size']\n",
    "            self.max_lattices = f.attrs['max_lattices']\n",
    "            self.num_samples = f.attrs['num_samples']\n",
    "            self.parameter_format = f.attrs['parameter_format']\n",
    "            print(f\"Dataset: {self.num_samples} samples, {self.image_size}x{self.image_size}, max {self.max_lattices} lattices\")\n",
    "            print(f\"Dataset path: {self.hdf5_path}\")\n",
    "    \n",
    "    def create_tf_dataset(self, batch_size=32, shuffle=True, validation_split=0.2):\n",
    "        \"\"\"Create TensorFlow datasets for training and validation\"\"\"\n",
    "        \n",
    "        def data_generator():\n",
    "            with h5py.File(self.hdf5_path, 'r') as f:\n",
    "                indices = np.arange(self.num_samples)\n",
    "                if shuffle:\n",
    "                    np.random.shuffle(indices)\n",
    "                \n",
    "                for idx in indices:\n",
    "                    image = f['images'][idx]\n",
    "                    params = f['parameters'][idx]\n",
    "                    yield image, params\n",
    "        \n",
    "        # Create dataset\n",
    "        dataset = tf.data.Dataset.from_generator(\n",
    "            data_generator,\n",
    "            output_signature=(\n",
    "                tf.TensorSpec(shape=(self.image_size, self.image_size, 1), dtype=tf.float32),\n",
    "                tf.TensorSpec(shape=(self.max_lattices * 5,), dtype=tf.float32)\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        # Split into train/validation\n",
    "        val_size = int(self.num_samples * validation_split)\n",
    "        train_size = self.num_samples - val_size\n",
    "        \n",
    "        train_dataset = dataset.take(train_size).batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
    "        val_dataset = dataset.skip(train_size).batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
    "        \n",
    "        return train_dataset, val_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "274e4c22",
   "metadata": {},
   "source": [
    "## 4. Neural Network Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6867bb4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_improved_lattice_cnn(input_shape=(128, 128, 1), max_lattices=8, param_per_lattice=5):\n",
    "    \"\"\"\n",
    "    Create a CNN optimized for periodic pattern detection\n",
    "    \n",
    "    Key design principles for moirÃ© lattice detection:\n",
    "    1. Global receptive field: Use dilated convolutions to capture long-range patterns\n",
    "    2. Multi-scale processing: Different scales for different lattice spacings\n",
    "    3. Frequency-aware features: Large kernels to detect periodicity\n",
    "    4. Global context: Self-attention and global pooling for full-image awareness\n",
    "    \"\"\"\n",
    "    inputs = tf.keras.Input(shape=input_shape)\n",
    "    \n",
    "    # === MULTI-SCALE FEATURE EXTRACTION ===\n",
    "    # Branch 1: Fine-scale features (small periods)\n",
    "    fine_branch = tf.keras.layers.Conv2D(32, (3, 3), activation='relu', padding='same')(inputs)\n",
    "    fine_branch = tf.keras.layers.Conv2D(32, (3, 3), activation='relu', padding='same')(fine_branch)\n",
    "    fine_pool = tf.keras.layers.MaxPooling2D((2, 2))(fine_branch)  # 64x64\n",
    "    \n",
    "    # Branch 2: Medium-scale features with dilated convolutions\n",
    "    medium_branch = tf.keras.layers.Conv2D(32, (5, 5), activation='relu', padding='same')(inputs)\n",
    "    medium_branch = tf.keras.layers.Conv2D(32, (5, 5), dilation_rate=2, activation='relu', padding='same')(medium_branch)\n",
    "    medium_pool = tf.keras.layers.MaxPooling2D((2, 2))(medium_branch)  # 64x64\n",
    "    \n",
    "    # Branch 3: Large-scale features with large kernels for long-range patterns\n",
    "    large_branch = tf.keras.layers.Conv2D(32, (7, 7), activation='relu', padding='same')(inputs)\n",
    "    large_branch = tf.keras.layers.Conv2D(32, (7, 7), dilation_rate=4, activation='relu', padding='same')(large_branch)\n",
    "    large_pool = tf.keras.layers.MaxPooling2D((2, 2))(large_branch)  # 64x64\n",
    "    \n",
    "    # Combine multi-scale features\n",
    "    combined = tf.keras.layers.Concatenate()([fine_pool, medium_pool, large_pool])  # 96 channels\n",
    "    \n",
    "    # === DILATED CONVOLUTION PYRAMID FOR GLOBAL CONTEXT ===\n",
    "    # Use different dilation rates to capture patterns at various scales\n",
    "    x = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same')(combined)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    \n",
    "    # Dilated convolution block 1 (dilation=2, ~7x7 receptive field)\n",
    "    dilated_1 = tf.keras.layers.Conv2D(64, (3, 3), dilation_rate=2, activation='relu', padding='same')(x)\n",
    "    \n",
    "    # Dilated convolution block 2 (dilation=4, ~15x15 receptive field)\n",
    "    dilated_2 = tf.keras.layers.Conv2D(64, (3, 3), dilation_rate=4, activation='relu', padding='same')(x)\n",
    "    \n",
    "    # Dilated convolution block 3 (dilation=8, ~31x31 receptive field)\n",
    "    dilated_3 = tf.keras.layers.Conv2D(64, (3, 3), dilation_rate=8, activation='relu', padding='same')(x)\n",
    "    \n",
    "    # Combine dilated features\n",
    "    dilated_combined = tf.keras.layers.Concatenate()([dilated_1, dilated_2, dilated_3])  # 192 channels\n",
    "    x = tf.keras.layers.Conv2D(128, (1, 1), activation='relu')(dilated_combined)  # Compress\n",
    "    x = tf.keras.layers.MaxPooling2D((2, 2))(x)  # 32x32\n",
    "    \n",
    "    # === GLOBAL CONTEXT BLOCK ===\n",
    "    # Global Average Pooling path for global context\n",
    "    global_context = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "    global_context = tf.keras.layers.Dense(256, activation='relu')(global_context)\n",
    "    global_context = tf.keras.layers.Dropout(0.3)(global_context)\n",
    "    \n",
    "    # Local feature path\n",
    "    x = tf.keras.layers.Conv2D(256, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.MaxPooling2D((2, 2))(x)  # 16x16\n",
    "    \n",
    "    # === FREQUENCY-AWARE PROCESSING ===\n",
    "    # Large kernel convolutions to detect periodic patterns\n",
    "    freq_features = tf.keras.layers.Conv2D(128, (7, 7), activation='relu', padding='same')(x)\n",
    "    freq_features = tf.keras.layers.Conv2D(128, (5, 5), activation='relu', padding='same')(freq_features)\n",
    "    \n",
    "    # Global pooling to aggregate all spatial information\n",
    "    spatial_features = tf.keras.layers.GlobalAveragePooling2D()(freq_features)\n",
    "    \n",
    "    # Combine global context with local features\n",
    "    combined_features = tf.keras.layers.Concatenate()([global_context, spatial_features])\n",
    "    \n",
    "    # === DENSE PROCESSING FOR PARAMETER REGRESSION ===\n",
    "    x = tf.keras.layers.Dense(512, activation='relu')(combined_features)\n",
    "    x = tf.keras.layers.Dropout(0.5)(x)\n",
    "    x = tf.keras.layers.Dense(256, activation='relu')(x)\n",
    "    x = tf.keras.layers.Dropout(0.3)(x)\n",
    "    \n",
    "    # === LATTICE-SPECIFIC HEADS ===\n",
    "    # Each lattice gets its own prediction head to handle variable numbers\n",
    "    lattice_outputs = []\n",
    "    for i in range(max_lattices):\n",
    "        # Lattice existence gate (decides if this lattice should be active)\n",
    "        gate = tf.keras.layers.Dense(64, activation='relu', name=f'lattice_{i}_gate')(x)\n",
    "        gate = tf.keras.layers.Dense(1, activation='sigmoid', name=f'lattice_{i}_existence')(gate)\n",
    "        \n",
    "        # Lattice parameter prediction\n",
    "        lattice_features = tf.keras.layers.Dense(64, activation='relu', name=f'lattice_{i}_features')(x)\n",
    "        lattice_params = tf.keras.layers.Dense(param_per_lattice-1, activation='linear', \n",
    "                                             name=f'lattice_{i}_raw_params')(lattice_features)\n",
    "        \n",
    "        # Combine existence gate with parameters\n",
    "        # Gate controls the magnitude of the spacing parameter\n",
    "        gated_params = tf.keras.layers.Multiply(name=f'lattice_{i}_gated')([lattice_params, \n",
    "                                                                           tf.keras.layers.Concatenate()([gate, gate, gate, gate])])\n",
    "        \n",
    "        # Add the existence probability as the first parameter (will be converted to spacing)\n",
    "        full_params = tf.keras.layers.Concatenate(name=f'lattice_{i}_params')([gate, gated_params])\n",
    "        \n",
    "        lattice_outputs.append(full_params)\n",
    "    \n",
    "    # Concatenate all lattice parameters\n",
    "    outputs = tf.keras.layers.Concatenate(name='all_lattice_params')(lattice_outputs)\n",
    "    \n",
    "    model = tf.keras.Model(inputs, outputs, name='PeriodicPatternCNN')\n",
    "    return model\n",
    "\n",
    "# Enhanced loss function for the new architecture\n",
    "@tf.function\n",
    "def enhanced_moire_loss(y_true, y_pred, image_size=128, alpha=1.0, beta=0.1, gamma=0.05):\n",
    "    \"\"\"\n",
    "    Enhanced loss function for periodic pattern detection\n",
    "    \n",
    "    Args:\n",
    "        y_true: true parameters\n",
    "        y_pred: predicted parameters  \n",
    "        alpha: reconstruction loss weight\n",
    "        beta: sparsity regularization weight\n",
    "        gamma: parameter smoothness weight\n",
    "    \"\"\"\n",
    "    # Basic parameter MSE loss\n",
    "    param_loss = tf.reduce_mean(tf.square(y_true - y_pred))\n",
    "    \n",
    "    # Reconstruction loss (render images and compare)\n",
    "    pred_images = hole_based_renderer(y_pred, image_size=image_size)\n",
    "    true_images = hole_based_renderer(y_true, image_size=image_size)\n",
    "    reconstruction_loss = tf.reduce_mean(tf.square(pred_images - true_images))\n",
    "    \n",
    "    # Sparsity regularization: encourage many lattices to be inactive\n",
    "    # The first parameter of each lattice is the existence gate\n",
    "    existence_gates = y_pred[:, ::5]  # Every 5th parameter starting from 0\n",
    "    sparsity_loss = tf.reduce_mean(existence_gates)  # Encourage sparsity\n",
    "    \n",
    "    # Parameter smoothness: prevent extreme parameter values\n",
    "    smoothness_loss = tf.reduce_mean(tf.square(y_pred))\n",
    "    \n",
    "    return param_loss + alpha * reconstruction_loss + beta * sparsity_loss + gamma * smoothness_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bf350ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fft_peak_extraction(image, num_peaks=8, min_distance=5):\n",
    "    \"\"\"\n",
    "    Extract peaks from 2D FFT for lattice parameter estimation\n",
    "    Updated for 128px images with better peak detection\n",
    "    \"\"\"\n",
    "    # Compute 2D FFT\n",
    "    fft_result = np.fft.fft2(image)\n",
    "    fft_shifted = np.fft.fftshift(fft_result)\n",
    "    magnitude = np.abs(fft_shifted)\n",
    "    phase = np.angle(fft_shifted)\n",
    "    \n",
    "    # Find peaks in magnitude spectrum (exclude DC component)\n",
    "    center = magnitude.shape[0] // 2\n",
    "    magnitude_copy = magnitude.copy()\n",
    "    magnitude_copy[center-3:center+4, center-3:center+4] = 0  # Larger DC exclusion for 128px\n",
    "    \n",
    "    # Apply maximum filter to find local maxima\n",
    "    neighborhood_size = max(5, min_distance)  # Larger neighborhood for 128px\n",
    "    local_maxima = maximum_filter(magnitude_copy, size=neighborhood_size)\n",
    "    \n",
    "    # Find positions where original equals local maximum (these are peaks)\n",
    "    peak_mask = (magnitude_copy == local_maxima) & (magnitude_copy > np.max(magnitude_copy) * 0.15)\n",
    "    peak_coords = np.where(peak_mask)\n",
    "    \n",
    "    if len(peak_coords[0]) == 0:\n",
    "        # Fallback: find top values manually\n",
    "        flat_indices = np.argsort(magnitude_copy.flatten())[::-1]\n",
    "        coords = np.unravel_index(flat_indices[:num_peaks*2], magnitude_copy.shape)\n",
    "        peak_coords = (coords[0], coords[1])\n",
    "    \n",
    "    # Get peak coordinates as (y, x) pairs\n",
    "    peaks = list(zip(peak_coords[0], peak_coords[1]))\n",
    "    \n",
    "    # Sort by magnitude and take top peaks\n",
    "    peak_magnitudes = [magnitude_copy[y, x] for y, x in peaks]\n",
    "    sorted_peaks = sorted(zip(peaks, peak_magnitudes), key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    # Extract top peaks\n",
    "    top_peaks = [peak[0] for peak in sorted_peaks[:num_peaks]]\n",
    "    \n",
    "    lattice_params = []\n",
    "    for peak in top_peaks:\n",
    "        y, x = peak\n",
    "        # Convert to k-space coordinates (relative to center)\n",
    "        ky = (y - center) * 2 * np.pi / image.shape[0]\n",
    "        kx = (x - center) * 2 * np.pi / image.shape[1]\n",
    "        \n",
    "        # Calculate parameters\n",
    "        k_magnitude = np.sqrt(kx**2 + ky**2)\n",
    "        if k_magnitude > 0:\n",
    "            theta = np.arctan2(ky, kx)\n",
    "            amplitude = magnitude[y, x] / np.max(magnitude)\n",
    "            phi = phase[y, x]\n",
    "            \n",
    "            lattice_params.append([theta, k_magnitude, phi, amplitude])\n",
    "    \n",
    "    return np.array(lattice_params)\n",
    "\n",
    "def fft_baseline_reconstruction(image, num_lattices=8):\n",
    "    \"\"\"\n",
    "    Baseline FFT-based reconstruction method\n",
    "    Updated for 128px images with adjusted parameter ranges\n",
    "    \"\"\"\n",
    "    # Extract FFT peaks\n",
    "    fft_params = fft_peak_extraction(image, num_peaks=num_lattices)\n",
    "    \n",
    "    if len(fft_params) == 0:\n",
    "        return np.zeros((num_lattices, 5))\n",
    "    \n",
    "    # Convert to our parameter format (theta, spacing, phase_x, phase_y, hole_radius)\n",
    "    converted_params = []\n",
    "    for i, params in enumerate(fft_params):\n",
    "        theta, k_mag, phi, amplitude = params\n",
    "        if k_mag > 0 and not np.isnan(k_mag) and not np.isnan(theta):\n",
    "            spacing = 2 * np.pi / k_mag\n",
    "            # Updated spacing range for 128px images (should match training constraints)\n",
    "            spacing = np.clip(spacing, 128//8, 128//3)  # 16 to 42 pixels\n",
    "            \n",
    "            # Estimate hole radius from amplitude, scaled for 128px\n",
    "            hole_radius = np.clip(amplitude * spacing * 0.15, 0.8, spacing / 4)\n",
    "            \n",
    "            # Normalize phase to [0, 2Ï€]\n",
    "            phase_x = (phi + np.pi) % (2 * np.pi)\n",
    "            phase_y = 0.0  # Set phase_y to 0 for simplicity\n",
    "            \n",
    "            converted_params.append([theta, spacing, phase_x, phase_y, hole_radius])\n",
    "    \n",
    "    # Pad to max_lattices with zeros\n",
    "    while len(converted_params) < num_lattices:\n",
    "        converted_params.append([0, 0, 0, 0, 0])  # Zero params = no contribution\n",
    "    \n",
    "    return np.array(converted_params[:num_lattices])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "984abe74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_moire_model(model, train_dataset, val_dataset, epochs=50, save_path='best_moire_model.h5'):\n",
    "    \"\"\"Train the moirÃ© lattice reconstruction model\"\"\"\n",
    "    \n",
    "    # Callbacks\n",
    "    callbacks = [\n",
    "        tf.keras.callbacks.ModelCheckpoint(\n",
    "            save_path, \n",
    "            save_best_only=True, \n",
    "            monitor='val_loss',\n",
    "            verbose=1\n",
    "        ),\n",
    "        tf.keras.callbacks.ReduceLROnPlateau(\n",
    "            monitor='val_loss',\n",
    "            factor=0.5,\n",
    "            patience=5,\n",
    "            min_lr=1e-6,\n",
    "            verbose=1\n",
    "        ),\n",
    "        tf.keras.callbacks.EarlyStopping(\n",
    "            monitor='val_loss',\n",
    "            patience=10,\n",
    "            restore_best_weights=True,\n",
    "            verbose=1\n",
    "        )\n",
    "    ]\n",
    "    \n",
    "    # Train model\n",
    "    history = model.fit(\n",
    "        train_dataset,\n",
    "        validation_data=val_dataset,\n",
    "        epochs=epochs,\n",
    "        callbacks=callbacks,\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    return history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17800137",
   "metadata": {},
   "source": [
    "## 7. Evaluation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "95ed0cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_reconstruction(model, test_images, test_params, num_samples=5):\n",
    "    \"\"\"Evaluate model reconstruction quality\"\"\"\n",
    "    \n",
    "    # Predict parameters\n",
    "    pred_params = model.predict(test_images[:num_samples])\n",
    "    \n",
    "    # Render images from predicted and true parameters\n",
    "    pred_images = hole_based_renderer(pred_params, image_size=test_images.shape[1])\n",
    "    true_images = hole_based_renderer(test_params[:num_samples], image_size=test_images.shape[1])\n",
    "    \n",
    "    # Calculate metrics\n",
    "    mse_reconstruction = tf.reduce_mean(tf.square(pred_images - test_images[:num_samples]))\n",
    "    mse_parameters = tf.reduce_mean(tf.square(pred_params - test_params[:num_samples]))\n",
    "    \n",
    "    # Visualize results\n",
    "    fig, axes = plt.subplots(num_samples, 4, figsize=(16, 4*num_samples))\n",
    "    if num_samples == 1:\n",
    "        axes = axes.reshape(1, -1)\n",
    "    \n",
    "    for i in range(num_samples):\n",
    "        # Original image\n",
    "        axes[i, 0].imshow(test_images[i, :, :, 0], cmap='gray')\n",
    "        axes[i, 0].set_title(f'Original Image {i+1}')\n",
    "        axes[i, 0].axis('off')\n",
    "        \n",
    "        # Predicted reconstruction\n",
    "        axes[i, 1].imshow(pred_images[i, :, :, 0], cmap='gray')\n",
    "        axes[i, 1].set_title(f'Predicted Reconstruction')\n",
    "        axes[i, 1].axis('off')\n",
    "        \n",
    "        # True reconstruction (from true parameters)\n",
    "        axes[i, 2].imshow(true_images[i, :, :, 0], cmap='gray')\n",
    "        axes[i, 2].set_title(f'True Reconstruction')\n",
    "        axes[i, 2].axis('off')\n",
    "        \n",
    "        # Difference\n",
    "        diff = np.abs(pred_images[i, :, :, 0] - test_images[i, :, :, 0])\n",
    "        axes[i, 3].imshow(diff, cmap='hot')\n",
    "        axes[i, 3].set_title(f'Abs Difference')\n",
    "        axes[i, 3].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"Reconstruction MSE: {mse_reconstruction:.6f}\")\n",
    "    print(f\"Parameter MSE: {mse_parameters:.6f}\")\n",
    "    \n",
    "    return mse_reconstruction, mse_parameters\n",
    "\n",
    "def plot_training_history(history):\n",
    "    \"\"\"Plot training and validation loss curves\"\"\"\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "    \n",
    "    # Loss plot\n",
    "    ax1.plot(history.history['loss'], label='Training Loss', linewidth=2)\n",
    "    ax1.plot(history.history['val_loss'], label='Validation Loss', linewidth=2)\n",
    "    ax1.set_xlabel('Epoch')\n",
    "    ax1.set_ylabel('Loss')\n",
    "    ax1.set_title('Model Loss During Training')\n",
    "    ax1.legend()\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    # MAE plot\n",
    "    ax2.plot(history.history['mae'], label='Training MAE', linewidth=2)\n",
    "    ax2.plot(history.history['val_mae'], label='Validation MAE', linewidth=2)\n",
    "    ax2.set_xlabel('Epoch')\n",
    "    ax2.set_ylabel('Mean Absolute Error')\n",
    "    ax2.set_title('Model MAE During Training')\n",
    "    ax2.legend()\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Print final metrics\n",
    "    final_train_loss = history.history['loss'][-1]\n",
    "    final_val_loss = history.history['val_loss'][-1]\n",
    "    final_train_mae = history.history['mae'][-1]\n",
    "    final_val_mae = history.history['val_mae'][-1]\n",
    "    \n",
    "    print(f\"Final Training Loss: {final_train_loss:.6f}\")\n",
    "    print(f\"Final Validation Loss: {final_val_loss:.6f}\")\n",
    "    print(f\"Final Training MAE: {final_train_mae:.6f}\")\n",
    "    print(f\"Final Validation MAE: {final_val_mae:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dab1d3e",
   "metadata": {},
   "source": [
    "## 8. Complete Pipeline Execution\n",
    "\n",
    "This cell runs the complete training pipeline with proper CUDA memory management."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95148c87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuring for CUDA memory management...\n",
      "ðŸš€ Starting Complete MoirÃ© Lattice Reconstruction Pipeline\n",
      "============================================================\n",
      "\n",
      "ðŸ“Š Creating training dataset (128x128 images)...\n",
      "Checking for existing dataset at moire_training_data_128px.h5...\n",
      "âœ… Found valid existing dataset with 5000 samples\n",
      "Using existing dataset!\n",
      "\n",
      "ðŸ“‚ Loading datasets...\n",
      "Dataset: 5000 samples, 128x128, max 8 lattices\n",
      "Dataset path: moire_training_data_128px.h5\n",
      "\n",
      "ðŸ§  Creating model for 128x128 images...\n",
      "Using optimized model architecture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1754358345.119566   12241 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9502 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4070 Ti, pci bus id: 0000:01:00.0, compute capability: 8.9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸŽ¯ Training model...\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1754358352.104549   12383 service.cc:152] XLA service 0x77b7c0002130 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1754358352.104586   12383 service.cc:160]   StreamExecutor device (0): NVIDIA GeForce RTX 4070 Ti, Compute Capability 8.9\n",
      "2025-08-05 01:45:52.272197: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "I0000 00:00:1754358353.919850   12383 cuda_dnn.cc:529] Loaded cuDNN version 90300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      1/Unknown \u001b[1m18s\u001b[0m 18s/step - loss: 99.2474 - mae: 4.5369"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-05 01:46:03.420276: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'input_add_reduce_subtract_fusion', 692 bytes spill stores, 692 bytes spill loads\n",
      "\n",
      "I0000 00:00:1754358363.477663   12383 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    708/Unknown \u001b[1m214s\u001b[0m 278ms/step - loss: 38.2286 - mae: 3.1487"
     ]
    }
   ],
   "source": [
    "def run_complete_pipeline(num_samples=5000, epochs=30, batch_size=32, image_size=128):\n",
    "    \"\"\"\n",
    "    Complete pipeline for moirÃ© lattice reconstruction with memory management\n",
    "    \n",
    "    Args:\n",
    "        num_samples: Number of training samples to generate\n",
    "        epochs: Number of training epochs\n",
    "        batch_size: Batch size for training\n",
    "        image_size: Size of images (default 128)\n",
    "    \"\"\"\n",
    "    print(\"ðŸš€ Starting Complete MoirÃ© Lattice Reconstruction Pipeline\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Clear any existing TF sessions and reset GPU\n",
    "    tf.keras.backend.clear_session()\n",
    "    \n",
    "    # Configure TensorFlow for better memory usage\n",
    "    # Disable cuDNN autotune which can cause memory issues\n",
    "    import os\n",
    "    os.environ['TF_CUDNN_USE_AUTOTUNE'] = '0'\n",
    "    \n",
    "    # Configure GPU memory growth\n",
    "    gpus = tf.config.list_physical_devices('GPU')\n",
    "    if gpus:\n",
    "        try:\n",
    "            for gpu in gpus:\n",
    "                tf.config.experimental.set_memory_growth(gpu, True)\n",
    "            # Optionally limit memory usage\n",
    "            # tf.config.set_logical_device_configuration(\n",
    "            #     gpus[0],\n",
    "            #     [tf.config.LogicalDeviceConfiguration(memory_limit=8192)]  # Limit to 8GB\n",
    "            # )\n",
    "        except RuntimeError as e:\n",
    "            print(f\"GPU configuration error: {e}\")\n",
    "    \n",
    "    # Paths\n",
    "    dataset_path = f'moire_training_data_{image_size}px.h5'\n",
    "    model_save_path = f'moire_model_trained_{image_size}px.h5'\n",
    "    \n",
    "    # Step 1: Create training data\n",
    "    print(f\"\\nðŸ“Š Creating training dataset ({image_size}x{image_size} images)...\")\n",
    "    create_training_dataset(\n",
    "        num_samples=num_samples,\n",
    "        image_size=image_size,\n",
    "        max_lattices=8,\n",
    "        save_path=dataset_path,\n",
    "        batch_size=100\n",
    "    )\n",
    "    \n",
    "    # Step 2: Load data\n",
    "    print(\"\\nðŸ“‚ Loading datasets...\")\n",
    "    data_loader = MoireDataLoader(dataset_path)\n",
    "    train_dataset, val_dataset = data_loader.create_tf_dataset(\n",
    "        batch_size=batch_size, \n",
    "        validation_split=0.2\n",
    "    )\n",
    "    \n",
    "    # Step 3: Create and compile model with correct input shape\n",
    "    print(f\"\\nðŸ§  Creating model for {image_size}x{image_size} images...\")\n",
    "    print(\"Using optimized model architecture\")\n",
    "    \n",
    "    model = create_improved_lattice_cnn(\n",
    "        input_shape=(image_size, image_size, 1),\n",
    "        max_lattices=8\n",
    "    )\n",
    "    \n",
    "    # Use mixed precision for memory efficiency\n",
    "    policy = tf.keras.mixed_precision.Policy('mixed_float16')\n",
    "    tf.keras.mixed_precision.set_global_policy(policy)\n",
    "    \n",
    "    # Compile with gradient clipping\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=0.001, clipnorm=1.0)\n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss='mse',\n",
    "        metrics=['mae']\n",
    "    )\n",
    "    \n",
    "    # Step 4: Train model\n",
    "    print(\"\\nðŸŽ¯ Training model...\")\n",
    "    try:\n",
    "        # Add more aggressive callbacks for memory management\n",
    "        callbacks = [\n",
    "            tf.keras.callbacks.ModelCheckpoint(\n",
    "                model_save_path, \n",
    "                save_best_only=True, \n",
    "                monitor='val_loss',\n",
    "                verbose=1\n",
    "            ),\n",
    "            tf.keras.callbacks.ReduceLROnPlateau(\n",
    "                monitor='val_loss',\n",
    "                factor=0.5,\n",
    "                patience=3,\n",
    "                min_lr=1e-6,\n",
    "                verbose=1\n",
    "            ),\n",
    "            tf.keras.callbacks.EarlyStopping(\n",
    "                monitor='val_loss',\n",
    "                patience=5,\n",
    "                restore_best_weights=True,\n",
    "                verbose=1\n",
    "            ),\n",
    "            # Garbage collection callback\n",
    "            tf.keras.callbacks.LambdaCallback(\n",
    "                on_epoch_end=lambda epoch, logs: tf.keras.backend.clear_session()\n",
    "            )\n",
    "        ]\n",
    "        \n",
    "        history = model.fit(\n",
    "            train_dataset,\n",
    "            validation_data=val_dataset,\n",
    "            epochs=epochs,\n",
    "            callbacks=callbacks,\n",
    "            verbose=1\n",
    "        )\n",
    "        \n",
    "        print(\"\\nâœ… Training completed!\")\n",
    "        \n",
    "        # Step 5: Plot training history\n",
    "        plot_training_history(history)\n",
    "        \n",
    "        # Step 6: Evaluate on validation samples\n",
    "        print(\"\\nðŸ“ˆ Evaluating model...\")\n",
    "        val_batch = next(iter(val_dataset))\n",
    "        val_images, val_params = val_batch\n",
    "        \n",
    "        # Evaluate on a small subset\n",
    "        mse_recon, mse_params = evaluate_reconstruction(\n",
    "            model, \n",
    "            val_images, \n",
    "            val_params, \n",
    "            num_samples=min(3, len(val_images))\n",
    "        )\n",
    "        \n",
    "        return model, history, data_loader\n",
    "        \n",
    "    except (tf.errors.ResourceExhaustedError, Exception) as e:\n",
    "        print(f\"\\nâŒ Error during training: {str(e)}\")\n",
    "        print(\"\\nðŸ”§ Attempting recovery with reduced batch size...\")\n",
    "        \n",
    "        # Clear everything and try with reduced settings\n",
    "        tf.keras.backend.clear_session()\n",
    "        \n",
    "        print(\"Retrying with reduced batch size...\")\n",
    "        return run_complete_pipeline(\n",
    "            num_samples=num_samples,\n",
    "            epochs=epochs,\n",
    "            batch_size=max(4, batch_size//2),  # Halve batch size\n",
    "            image_size=image_size\n",
    "        )\n",
    "    finally:\n",
    "        # Always clear session to free memory\n",
    "        tf.keras.backend.clear_session()\n",
    "\n",
    "# Run the pipeline with conservative settings and memory management\n",
    "print(\"Configuring for CUDA memory management...\")\n",
    "model, history, data_loader = run_complete_pipeline(\n",
    "    num_samples=5000,  # Start smaller\n",
    "    epochs=100,         # Fewer epochs for testing\n",
    "    batch_size=8,      # Smaller batch size for memory (reduced from 16)\n",
    "    image_size=128     # Use 128x128 for initial testing\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdc3f179",
   "metadata": {},
   "source": [
    "## 9. Comprehensive Model Evaluation\n",
    "\n",
    "Now that the model is trained, let's perform detailed evaluation and analysis of the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "188bf9e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run dataset visualization now that we have the data_loader\n",
    "if 'data_loader' in locals() and data_loader is not None:\n",
    "    print(\"\\\\n\" + \"=\"*60)\n",
    "    print(\"ðŸ“Š DATASET ANALYSIS\")\n",
    "    print(\"=\"*60)\n",
    "    visualize_dataset(data_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15fb40b7",
   "metadata": {},
   "source": [
    "## 8.5. Dataset Visualization and Analysis\n",
    "\n",
    "Let's examine the training dataset to understand the diversity and quality of generated patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a7bc3fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_dataset(data_loader, num_examples=20):\n",
    "    \"\"\"\n",
    "    Comprehensive visualization of the training dataset\n",
    "    \"\"\"\n",
    "    print(\"ðŸŽ¨ Dataset Visualization and Analysis\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Load dataset\n",
    "    train_dataset, val_dataset = data_loader.create_tf_dataset(batch_size=32, validation_split=0.2)\n",
    "    \n",
    "    # Get a batch for analysis\n",
    "    train_batch = next(iter(train_dataset))\n",
    "    images, params = train_batch\n",
    "    \n",
    "    # 1. Sample Images Grid\n",
    "    fig, axes = plt.subplots(4, 5, figsize=(15, 12))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    for i in range(min(20, len(images))):\n",
    "        axes[i].imshow(images[i, :, :, 0], cmap='gray', vmin=0, vmax=1)\n",
    "        \n",
    "        # Count active lattices for this sample\n",
    "        sample_params = params[i].numpy()\n",
    "        active_lattices = np.sum(sample_params[1::5] > 0.5)  # Count non-zero spacings\n",
    "        \n",
    "        axes[i].set_title(f'Sample {i+1}\\\\n{active_lattices} lattices', fontsize=10)\n",
    "        axes[i].axis('off')\n",
    "    \n",
    "    plt.suptitle('Dataset Sample Images', fontsize=16, y=0.95)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # 2. Parameter Distribution Analysis\n",
    "    all_params = []\n",
    "    all_images = []\n",
    "    lattice_counts = []\n",
    "    \n",
    "    # Collect multiple batches for statistical analysis\n",
    "    batch_count = 0\n",
    "    for batch in train_dataset:\n",
    "        if batch_count >= 5:  # Analyze first 5 batches\n",
    "            break\n",
    "        batch_images, batch_params = batch\n",
    "        all_params.append(batch_params.numpy())\n",
    "        all_images.append(batch_images.numpy())\n",
    "        \n",
    "        # Count lattices per sample\n",
    "        for sample_idx in range(len(batch_params)):\n",
    "            sample_params = batch_params[sample_idx].numpy()\n",
    "            active_count = np.sum(sample_params[1::5] > 0.5)\n",
    "            lattice_counts.append(active_count)\n",
    "        \n",
    "        batch_count += 1\n",
    "    \n",
    "    all_params = np.concatenate(all_params, axis=0)\n",
    "    all_images = np.concatenate(all_images, axis=0)\n",
    "    lattice_counts = np.array(lattice_counts)\n",
    "    \n",
    "    # 3. Parameter Distribution Plots\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "    param_names = ['Theta (rad)', 'Spacing (px)', 'Phase X (rad)', 'Phase Y (rad)', 'Hole Radius (px)']\n",
    "    \n",
    "    for param_idx in range(5):\n",
    "        row = param_idx // 3\n",
    "        col = param_idx % 3\n",
    "        ax = axes[row, col]\n",
    "        \n",
    "        # Extract parameter values for all active lattices\n",
    "        param_values = []\n",
    "        for lattice_idx in range(8):  # max 8 lattices\n",
    "            param_pos = lattice_idx * 5 + param_idx\n",
    "            values = all_params[:, param_pos]\n",
    "            # Only include active lattices (non-zero spacing)\n",
    "            if param_idx == 1:  # spacing parameter\n",
    "                active_values = values[values > 0.5]\n",
    "            else:\n",
    "                # For other parameters, use spacing to determine if lattice is active\n",
    "                spacing_pos = lattice_idx * 5 + 1\n",
    "                spacing_values = all_params[:, spacing_pos]\n",
    "                active_mask = spacing_values > 0.5\n",
    "                active_values = values[active_mask]\n",
    "            \n",
    "            param_values.extend(active_values)\n",
    "        \n",
    "        if len(param_values) > 0:\n",
    "            ax.hist(param_values, bins=50, alpha=0.7, edgecolor='black', linewidth=0.5)\n",
    "            ax.set_xlabel(param_names[param_idx])\n",
    "            ax.set_ylabel('Frequency')\n",
    "            ax.set_title(f'{param_names[param_idx]} Distribution\\\\n({len(param_values)} active values)')\n",
    "            ax.grid(True, alpha=0.3)\n",
    "            \n",
    "            # Add statistics\n",
    "            mean_val = np.mean(param_values)\n",
    "            std_val = np.std(param_values)\n",
    "            ax.axvline(mean_val, color='red', linestyle='--', label=f'Mean: {mean_val:.2f}')\n",
    "            ax.axvline(mean_val + std_val, color='orange', linestyle=':', alpha=0.7, label=f'Â±1Ïƒ: {std_val:.2f}')\n",
    "            ax.axvline(mean_val - std_val, color='orange', linestyle=':', alpha=0.7)\n",
    "            ax.legend(fontsize=8)\n",
    "    \n",
    "    # Remove unused subplot\n",
    "    axes[1, 2].remove()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # 4. Lattice Count Distribution\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
    "    \n",
    "    # Histogram of lattice counts\n",
    "    ax = axes[0]\n",
    "    unique_counts, count_frequencies = np.unique(lattice_counts, return_counts=True)\n",
    "    ax.bar(unique_counts, count_frequencies, alpha=0.7, edgecolor='black')\n",
    "    ax.set_xlabel('Number of Active Lattices')\n",
    "    ax.set_ylabel('Frequency')\n",
    "    ax.set_title('Distribution of Lattice Counts in Dataset')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Add percentage labels\n",
    "    total_samples = len(lattice_counts)\n",
    "    for count, freq in zip(unique_counts, count_frequencies):\n",
    "        percentage = (freq / total_samples) * 100\n",
    "        ax.text(count, freq + max(count_frequencies) * 0.01, f'{percentage:.1f}%', \n",
    "                ha='center', va='bottom', fontsize=10)\n",
    "    \n",
    "    # Complexity analysis\n",
    "    ax = axes[1]\n",
    "    # Create complexity score based on number of lattices and parameter variance\n",
    "    complexity_scores = []\n",
    "    for i in range(len(all_params)):\n",
    "        sample_params = all_params[i]\n",
    "        active_lattices = np.sum(sample_params[1::5] > 0.5)\n",
    "        \n",
    "        # Calculate parameter variance for active lattices\n",
    "        active_params = []\n",
    "        for lat_idx in range(8):\n",
    "            if sample_params[lat_idx * 5 + 1] > 0.5:  # If spacing > 0.5\n",
    "                active_params.extend(sample_params[lat_idx*5:(lat_idx+1)*5])\n",
    "        \n",
    "        if len(active_params) > 0:\n",
    "            param_variance = np.var(active_params)\n",
    "            complexity = active_lattices * (1 + param_variance * 0.1)  # Weight by variance\n",
    "        else:\n",
    "            complexity = 0\n",
    "        complexity_scores.append(complexity)\n",
    "    \n",
    "    ax.scatter(lattice_counts, complexity_scores, alpha=0.6, s=20)\n",
    "    ax.set_xlabel('Number of Active Lattices')\n",
    "    ax.set_ylabel('Complexity Score')\n",
    "    ax.set_title('Pattern Complexity vs Lattice Count')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # 5. Image Statistics\n",
    "    print(f\"\\\\nðŸ“Š Dataset Statistics:\")\n",
    "    print(f\"  Total samples analyzed: {len(all_images)}\")\n",
    "    print(f\"  Image shape: {all_images.shape[1:3]}\")\n",
    "    print(f\"  Pixel value range: [{np.min(all_images):.3f}, {np.max(all_images):.3f}]\")\n",
    "    print(f\"  Mean pixel value: {np.mean(all_images):.3f}\")\n",
    "    print(f\"  Pixel std: {np.std(all_images):.3f}\")\n",
    "    print(f\"  \\\\nLattice count distribution:\")\n",
    "    for count, freq in zip(unique_counts, count_frequencies):\n",
    "        percentage = (freq / total_samples) * 100\n",
    "        print(f\"    {count} lattices: {freq:4d} samples ({percentage:5.1f}%)\")\n",
    "    \n",
    "    print(f\"  \\\\nAverage lattices per sample: {np.mean(lattice_counts):.2f}\")\n",
    "    print(f\"  Max lattices in sample: {np.max(lattice_counts)}\")\n",
    "    \n",
    "    # 6. Sample complexity examples\n",
    "    print(f\"\\\\nðŸŽ¯ Showing examples by complexity:\")\n",
    "    complexity_indices = np.argsort(complexity_scores)\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 5, figsize=(15, 8))\n",
    "    \n",
    "    # Simple patterns (low complexity)\n",
    "    for i in range(5):\n",
    "        idx = complexity_indices[i * len(complexity_indices) // 10]  # Spread across range\n",
    "        axes[0, i].imshow(all_images[idx, :, :, 0], cmap='gray', vmin=0, vmax=1)\n",
    "        axes[0, i].set_title(f'Simple\\\\n{lattice_counts[idx]} lattices\\\\nScore: {complexity_scores[idx]:.1f}')\n",
    "        axes[0, i].axis('off')\n",
    "    \n",
    "    # Complex patterns (high complexity)\n",
    "    for i in range(5):\n",
    "        idx = complexity_indices[-(i+1) * len(complexity_indices) // 10]\n",
    "        axes[1, i].imshow(all_images[idx, :, :, 0], cmap='gray', vmin=0, vmax=1)\n",
    "        axes[1, i].set_title(f'Complex\\\\n{lattice_counts[idx]} lattices\\\\nScore: {complexity_scores[idx]:.1f}')\n",
    "        axes[1, i].axis('off')\n",
    "    \n",
    "    plt.suptitle('Dataset Complexity Examples', fontsize=16)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Run dataset visualization if we have data_loader\n",
    "if 'data_loader' in locals() and data_loader is not None:\n",
    "    visualize_dataset(data_loader)\n",
    "else:\n",
    "    print(\"ðŸ“Š Dataset visualization will run after training pipeline creates data_loader\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cccc5a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_memory_usage(batch_size, image_size, max_lattices=8):\n",
    "    \"\"\"\n",
    "    Estimate GPU memory usage for different training configurations\n",
    "    \"\"\"\n",
    "    print(\"ðŸ” GPU Memory Usage Estimation\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Model parameter estimation (rough)\n",
    "    # Based on the improved CNN architecture\n",
    "    \n",
    "    # Input: batch_size x image_size x image_size x 1\n",
    "    input_memory = batch_size * image_size * image_size * 1 * 4  # float32 = 4 bytes\n",
    "    \n",
    "    # Convolutional layers (rough estimation)\n",
    "    # Conv layers create intermediate feature maps\n",
    "    conv_memory = batch_size * image_size * image_size * 256 * 4  # Assume 256 max channels\n",
    "    \n",
    "    # Dense layers\n",
    "    dense_features = 512  # From the architecture\n",
    "    dense_memory = batch_size * dense_features * 4\n",
    "    \n",
    "    # Output: batch_size x (max_lattices * 5)\n",
    "    output_memory = batch_size * max_lattices * 5 * 4\n",
    "    \n",
    "    # Gradient memory (roughly 2x model parameters)\n",
    "    gradient_memory = 2 * (conv_memory + dense_memory)\n",
    "    \n",
    "    # Optimizer states (Adam needs ~2x parameters)\n",
    "    optimizer_memory = 2 * (conv_memory + dense_memory)\n",
    "    \n",
    "    total_memory_bytes = (input_memory + conv_memory + dense_memory + \n",
    "                         output_memory + gradient_memory + optimizer_memory)\n",
    "    \n",
    "    total_memory_gb = total_memory_bytes / (1024**3)\n",
    "    \n",
    "    print(f\"Estimated memory usage for batch_size={batch_size}, image_size={image_size}:\")\n",
    "    print(f\"  Input tensors:     {input_memory / (1024**2):6.1f} MB\")\n",
    "    print(f\"  Conv features:     {conv_memory / (1024**2):6.1f} MB\") \n",
    "    print(f\"  Dense features:    {dense_memory / (1024**2):6.1f} MB\")\n",
    "    print(f\"  Output tensors:    {output_memory / (1024**2):6.1f} MB\")\n",
    "    print(f\"  Gradients:         {gradient_memory / (1024**2):6.1f} MB\")\n",
    "    print(f\"  Optimizer states:  {optimizer_memory / (1024**2):6.1f} MB\")\n",
    "    print(f\"  â”€\" * 40)\n",
    "    print(f\"  TOTAL:            {total_memory_gb:6.2f} GB\")\n",
    "    \n",
    "    # Safety recommendations\n",
    "    if total_memory_gb < 4:\n",
    "        print(\"  âœ… Should fit comfortably on most GPUs\")\n",
    "    elif total_memory_gb < 8:\n",
    "        print(\"  âš¡ Should work on 8GB+ GPUs\")\n",
    "    elif total_memory_gb < 12:\n",
    "        print(\"  âš ï¸  Needs 12GB+ GPU, might be tight\")\n",
    "    else:\n",
    "        print(\"  âŒ Likely too large for most consumer GPUs\")\n",
    "    \n",
    "    return total_memory_gb\n",
    "\n",
    "def find_optimal_batch_size(target_memory_gb=8, image_size=128):\n",
    "    \"\"\"\n",
    "    Find the largest batch size that fits in target memory\n",
    "    \"\"\"\n",
    "    print(f\"\\\\nðŸŽ¯ Finding optimal batch size for {target_memory_gb}GB GPU:\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    optimal_batch = 1\n",
    "    for batch_size in range(1, 33):  # Test up to batch size 32\n",
    "        estimated_memory = estimate_memory_usage(batch_size, image_size)\n",
    "        if estimated_memory <= target_memory_gb * 0.8:  # Use 80% of available memory for safety\n",
    "            optimal_batch = batch_size\n",
    "        else:\n",
    "            break\n",
    "    \n",
    "    print(f\"\\\\nðŸ’¡ Recommended batch size: {optimal_batch}\")\n",
    "    print(f\"   (Uses ~{estimate_memory_usage(optimal_batch, image_size):.1f}GB of {target_memory_gb}GB available)\")\n",
    "    \n",
    "    return optimal_batch\n",
    "\n",
    "# Test current configuration\n",
    "print(\"Current configuration analysis:\")\n",
    "estimate_memory_usage(batch_size=6, image_size=128)\n",
    "\n",
    "# Find optimal batch size for your GPU\n",
    "optimal_batch = find_optimal_batch_size(target_memory_gb=9, image_size=128)  # Conservative 9GB estimate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3b7ba0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_training_config(gpu_memory_gb=9, target_accuracy='high'):\n",
    "    \"\"\"\n",
    "    Recommend optimal training configuration based on available resources\n",
    "    \n",
    "    Args:\n",
    "        gpu_memory_gb: Available GPU memory in GB\n",
    "        target_accuracy: 'fast', 'balanced', or 'high'\n",
    "    \"\"\"\n",
    "    print(\"âš™ï¸ Training Configuration Optimizer\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Find optimal batch size for available memory\n",
    "    optimal_batch = find_optimal_batch_size(target_memory_gb=gpu_memory_gb, image_size=128)\n",
    "    \n",
    "    # Configuration recommendations based on target\n",
    "    configs = {\n",
    "        'fast': {\n",
    "            'num_samples': 4000,\n",
    "            'epochs': 15,\n",
    "            'description': 'Quick training for testing and prototyping'\n",
    "        },\n",
    "        'balanced': {\n",
    "            'num_samples': 8000,\n",
    "            'epochs': 25,\n",
    "            'description': 'Good balance of quality and training time'\n",
    "        },\n",
    "        'high': {\n",
    "            'num_samples': 15000,\n",
    "            'epochs': 40,\n",
    "            'description': 'High quality results, longer training time'\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    config = configs[target_accuracy]\n",
    "    recommended_batch = min(optimal_batch, 8)  # Cap at 8 for stability\n",
    "    \n",
    "    print(f\"\\\\nðŸŽ¯ Recommended Configuration ({target_accuracy} accuracy):\")\n",
    "    print(f\"  GPU Memory: {gpu_memory_gb}GB\")\n",
    "    print(f\"  Batch Size: {recommended_batch}\")\n",
    "    print(f\"  Dataset Size: {config['num_samples']:,} samples\")\n",
    "    print(f\"  Epochs: {config['epochs']}\")\n",
    "    print(f\"  Description: {config['description']}\")\n",
    "    \n",
    "    # Calculate training time estimate\n",
    "    samples_per_epoch = config['num_samples'] * 0.8  # 80% for training\n",
    "    steps_per_epoch = int(samples_per_epoch / recommended_batch)\n",
    "    total_steps = steps_per_epoch * config['epochs']\n",
    "    \n",
    "    # Rough timing estimate (based on your GPU performance)\n",
    "    seconds_per_step = 0.15  # Conservative estimate\n",
    "    total_time_hours = (total_steps * seconds_per_step) / 3600\n",
    "    \n",
    "    print(f\"\\\\nâ±ï¸ Training Time Estimate:\")\n",
    "    print(f\"  Steps per epoch: {steps_per_epoch}\")\n",
    "    print(f\"  Total steps: {total_steps:,}\")\n",
    "    print(f\"  Estimated time: {total_time_hours:.1f} hours\")\n",
    "    \n",
    "    # Memory usage check\n",
    "    memory_usage = estimate_memory_usage(recommended_batch, 128)\n",
    "    memory_utilization = (memory_usage / gpu_memory_gb) * 100\n",
    "    \n",
    "    print(f\"\\\\nðŸ’¾ Memory Analysis:\")\n",
    "    print(f\"  Estimated usage: {memory_usage:.1f}GB ({memory_utilization:.0f}% of available)\")\n",
    "    \n",
    "    if memory_utilization < 60:\n",
    "        print(\"  âœ… Conservative - could potentially use larger batch size\")\n",
    "    elif memory_utilization < 80:\n",
    "        print(\"  âš¡ Optimal - good memory utilization\")\n",
    "    else:\n",
    "        print(\"  âš ï¸  High - might need to reduce batch size if errors occur\")\n",
    "    \n",
    "    # Generate the code\n",
    "    print(f\"\\\\nðŸ’» Recommended Code:\")\n",
    "    print(\"```python\")\n",
    "    print(\"model, history, data_loader = run_complete_pipeline(\")\n",
    "    print(f\"    num_samples={config['num_samples']},\")\n",
    "    print(f\"    epochs={config['epochs']},\")\n",
    "    print(f\"    batch_size={recommended_batch},\")\n",
    "    print(\"    image_size=128\")\n",
    "    print(\")\")\n",
    "    print(\"```\")\n",
    "    \n",
    "    return {\n",
    "        'num_samples': config['num_samples'],\n",
    "        'epochs': config['epochs'],\n",
    "        'batch_size': recommended_batch,\n",
    "        'image_size': 128,\n",
    "        'estimated_time_hours': total_time_hours,\n",
    "        'memory_usage_gb': memory_usage\n",
    "    }\n",
    "\n",
    "# Test different configurations\n",
    "print(\"ðŸš€ Configuration Analysis for Your Setup:\")\n",
    "print()\n",
    "\n",
    "fast_config = optimize_training_config(gpu_memory_gb=9, target_accuracy='fast')\n",
    "print(\"\\\\n\" + \"=\"*60)\n",
    "balanced_config = optimize_training_config(gpu_memory_gb=9, target_accuracy='balanced')\n",
    "print(\"\\\\n\" + \"=\"*60)\n",
    "high_config = optimize_training_config(gpu_memory_gb=9, target_accuracy='high')\n",
    "\n",
    "print(f\"\\\\nðŸŽ² Current Configuration (in the notebook):\")\n",
    "print(f\"  num_samples=8000, epochs=25, batch_size=6\")\n",
    "print(f\"  This matches the 'balanced' recommendation! âœ…\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7abcec46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detailed_parameter_analysis(model, data_loader, num_samples=10):\n",
    "    \"\"\"\n",
    "    Analyze model predictions vs ground truth parameters in detail\n",
    "    \"\"\"\n",
    "    print(\"ðŸ” Detailed Parameter Analysis\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Get validation data\n",
    "    val_dataset = data_loader.create_tf_dataset(batch_size=32, validation_split=0.2)[1]\n",
    "    val_batch = next(iter(val_dataset))\n",
    "    val_images, val_params = val_batch\n",
    "    \n",
    "    # Get predictions\n",
    "    predictions = model.predict(val_images[:num_samples])\n",
    "    true_params = val_params[:num_samples].numpy()\n",
    "    \n",
    "    # Analyze each parameter type\n",
    "    param_names = ['theta', 'spacing', 'phase_x', 'phase_y', 'hole_radius']\n",
    "    max_lattices = 8\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    for param_idx in range(5):\n",
    "        ax = axes[param_idx]\n",
    "        \n",
    "        # Extract parameter values for all lattices\n",
    "        true_vals = []\n",
    "        pred_vals = []\n",
    "        \n",
    "        for lattice_idx in range(max_lattices):\n",
    "            param_pos = lattice_idx * 5 + param_idx\n",
    "            true_vals.extend(true_params[:, param_pos])\n",
    "            pred_vals.extend(predictions[:, param_pos])\n",
    "        \n",
    "        # Filter out zero parameters (inactive lattices)\n",
    "        non_zero_mask = np.array(true_vals) > 1e-6\n",
    "        true_vals = np.array(true_vals)[non_zero_mask]\n",
    "        pred_vals = np.array(pred_vals)[non_zero_mask]\n",
    "        \n",
    "        if len(true_vals) > 0:\n",
    "            # Scatter plot\n",
    "            ax.scatter(true_vals, pred_vals, alpha=0.6, s=20)\n",
    "            \n",
    "            # Perfect prediction line\n",
    "            min_val, max_val = min(true_vals.min(), pred_vals.min()), max(true_vals.max(), pred_vals.max())\n",
    "            ax.plot([min_val, max_val], [min_val, max_val], 'r--', label='Perfect prediction')\n",
    "            \n",
    "            # Calculate metrics\n",
    "            mae = np.mean(np.abs(true_vals - pred_vals))\n",
    "            r2 = 1 - np.sum((true_vals - pred_vals)**2) / np.sum((true_vals - np.mean(true_vals))**2)\n",
    "            \n",
    "            ax.set_xlabel(f'True {param_names[param_idx]}')\n",
    "            ax.set_ylabel(f'Predicted {param_names[param_idx]}')\n",
    "            ax.set_title(f'{param_names[param_idx]}\\nMAE: {mae:.4f}, RÂ²: {r2:.4f}')\n",
    "            ax.legend()\n",
    "            ax.grid(True, alpha=0.3)\n",
    "        else:\n",
    "            ax.text(0.5, 0.5, f'No active\\n{param_names[param_idx]}', \n",
    "                   transform=ax.transAxes, ha='center', va='center')\n",
    "            ax.set_title(param_names[param_idx])\n",
    "    \n",
    "    # Remove unused subplot\n",
    "    axes[5].remove()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Print detailed statistics\n",
    "    print(\"\\nðŸ“Š Parameter Statistics:\")\n",
    "    for param_idx in range(5):\n",
    "        true_vals = []\n",
    "        pred_vals = []\n",
    "        \n",
    "        for lattice_idx in range(max_lattices):\n",
    "            param_pos = lattice_idx * 5 + param_idx\n",
    "            true_vals.extend(true_params[:, param_pos])\n",
    "            pred_vals.extend(predictions[:, param_pos])\n",
    "        \n",
    "        non_zero_mask = np.array(true_vals) > 1e-6\n",
    "        true_vals = np.array(true_vals)[non_zero_mask]\n",
    "        pred_vals = np.array(pred_vals)[non_zero_mask]\n",
    "        \n",
    "        if len(true_vals) > 0:\n",
    "            mae = np.mean(np.abs(true_vals - pred_vals))\n",
    "            rmse = np.sqrt(np.mean((true_vals - pred_vals)**2))\n",
    "            r2 = 1 - np.sum((true_vals - pred_vals)**2) / np.sum((true_vals - np.mean(true_vals))**2)\n",
    "            \n",
    "            print(f\"  {param_names[param_idx]:12s}: MAE={mae:7.4f}, RMSE={rmse:7.4f}, RÂ²={r2:7.4f}\")\n",
    "\n",
    "# Run the analysis if we have a trained model\n",
    "if 'model' in locals() and model is not None:\n",
    "    detailed_parameter_analysis(model, data_loader, num_samples=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e217efa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visual_reconstruction_comparison(model, data_loader, num_examples=6):\n",
    "    \"\"\"\n",
    "    Compare original images with reconstructed images from predicted parameters\n",
    "    \"\"\"\n",
    "    print(\"ðŸŽ¨ Visual Reconstruction Comparison\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Get validation data\n",
    "    val_dataset = data_loader.create_tf_dataset(batch_size=32, validation_split=0.2)[1]\n",
    "    val_batch = next(iter(val_dataset))\n",
    "    val_images, val_params = val_batch\n",
    "    \n",
    "    # Get predictions\n",
    "    predictions = model.predict(val_images[:num_examples])\n",
    "    \n",
    "    # Render reconstructed images\n",
    "    reconstructed = hole_based_renderer(predictions, image_size=128)\n",
    "    \n",
    "    # Create comparison plot\n",
    "    fig, axes = plt.subplots(3, num_examples, figsize=(3*num_examples, 9))\n",
    "    \n",
    "    for i in range(num_examples):\n",
    "        # Original image\n",
    "        axes[0, i].imshow(val_images[i, :, :, 0], cmap='gray', vmin=0, vmax=1)\n",
    "        axes[0, i].set_title(f'Original {i+1}')\n",
    "        axes[0, i].axis('off')\n",
    "        \n",
    "        # Reconstructed image\n",
    "        axes[1, i].imshow(reconstructed[i, :, :, 0], cmap='gray', vmin=0, vmax=1)\n",
    "        axes[1, i].set_title(f'Reconstructed {i+1}')\n",
    "        axes[1, i].axis('off')\n",
    "        \n",
    "        # Difference\n",
    "        diff = np.abs(val_images[i, :, :, 0] - reconstructed[i, :, :, 0])\n",
    "        im = axes[2, i].imshow(diff, cmap='Reds', vmin=0, vmax=np.max(diff))\n",
    "        axes[2, i].set_title(f'Difference {i+1}\\nMAE: {np.mean(diff):.4f}')\n",
    "        axes[2, i].axis('off')\n",
    "        \n",
    "        # Add colorbar for difference\n",
    "        plt.colorbar(im, ax=axes[2, i], fraction=0.046, pad=0.04)\n",
    "    \n",
    "    plt.suptitle('Visual Reconstruction Quality Assessment', fontsize=16, y=0.95)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Calculate overall reconstruction metrics\n",
    "    all_original = val_images[:num_examples]\n",
    "    all_reconstructed = reconstructed\n",
    "    \n",
    "    reconstruction_mae = np.mean(np.abs(all_original - all_reconstructed))\n",
    "    reconstruction_mse = np.mean((all_original - all_reconstructed)**2)\n",
    "    ssim_scores = []\n",
    "    \n",
    "    try:\n",
    "        from skimage.metrics import structural_similarity as ssim\n",
    "        for i in range(num_examples):\n",
    "            ssim_score = ssim(all_original[i, :, :, 0], all_reconstructed[i, :, :, 0])\n",
    "            ssim_scores.append(ssim_score)\n",
    "        avg_ssim = np.mean(ssim_scores)\n",
    "        print(f\"\\nðŸ“Š Reconstruction Metrics:\")\n",
    "        print(f\"  MAE: {reconstruction_mae:.6f}\")\n",
    "        print(f\"  MSE: {reconstruction_mse:.6f}\")\n",
    "        print(f\"  SSIM: {avg_ssim:.4f}\")\n",
    "    except ImportError:\n",
    "        print(f\"\\nðŸ“Š Reconstruction Metrics:\")\n",
    "        print(f\"  MAE: {reconstruction_mae:.6f}\")\n",
    "        print(f\"  MSE: {reconstruction_mse:.6f}\")\n",
    "        print(\"  SSIM: (requires scikit-image)\")\n",
    "\n",
    "# Run the visual comparison if we have a trained model\n",
    "if 'model' in locals() and model is not None:\n",
    "    visual_reconstruction_comparison(model, data_loader, num_examples=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14dba7fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lattice_count_analysis(model, data_loader, num_samples=100):\n",
    "    \"\"\"\n",
    "    Analyze how well the model predicts the number of active lattices\n",
    "    \"\"\"\n",
    "    print(\"ðŸ”¢ Lattice Count and Sparsity Analysis\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Get validation data\n",
    "    val_dataset = data_loader.create_tf_dataset(batch_size=32, validation_split=0.2)[1]\n",
    "    \n",
    "    true_counts = []\n",
    "    pred_counts = []\n",
    "    existence_probs = []\n",
    "    \n",
    "    samples_processed = 0\n",
    "    for batch in val_dataset:\n",
    "        if samples_processed >= num_samples:\n",
    "            break\n",
    "            \n",
    "        val_images, val_params = batch\n",
    "        batch_size = val_images.shape[0]\n",
    "        \n",
    "        # Get predictions\n",
    "        predictions = model.predict(val_images, verbose=0)\n",
    "        \n",
    "        for i in range(min(batch_size, num_samples - samples_processed)):\n",
    "            # Count true active lattices (spacing > threshold)\n",
    "            true_spacings = val_params[i, 1::5].numpy()  # Every 5th param starting from 1\n",
    "            true_count = np.sum(true_spacings > 0.5)\n",
    "            true_counts.append(true_count)\n",
    "            \n",
    "            # Count predicted active lattices\n",
    "            pred_spacings = predictions[i, 1::5]  # Every 5th param starting from 1\n",
    "            pred_count = np.sum(pred_spacings > 0.5)\n",
    "            pred_counts.append(pred_count)\n",
    "            \n",
    "            # Store existence probabilities (first param of each lattice)\n",
    "            existence_gates = predictions[i, ::5]  # Every 5th param starting from 0\n",
    "            existence_probs.append(existence_gates)\n",
    "        \n",
    "        samples_processed += batch_size\n",
    "    \n",
    "    true_counts = np.array(true_counts[:num_samples])\n",
    "    pred_counts = np.array(pred_counts[:num_samples])\n",
    "    existence_probs = np.array(existence_probs[:num_samples])\n",
    "    \n",
    "    # Create analysis plots\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "    \n",
    "    # Count comparison histogram\n",
    "    ax = axes[0, 0]\n",
    "    max_count = max(np.max(true_counts), np.max(pred_counts)) + 1\n",
    "    bins = np.arange(-0.5, max_count + 0.5, 1)\n",
    "    \n",
    "    ax.hist(true_counts, bins=bins, alpha=0.6, label='True counts', density=True)\n",
    "    ax.hist(pred_counts, bins=bins, alpha=0.6, label='Predicted counts', density=True)\n",
    "    ax.set_xlabel('Number of Active Lattices')\n",
    "    ax.set_ylabel('Density')\n",
    "    ax.set_title('Distribution of Lattice Counts')\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Count accuracy scatter plot\n",
    "    ax = axes[0, 1]\n",
    "    ax.scatter(true_counts, pred_counts, alpha=0.6)\n",
    "    ax.plot([0, max_count], [0, max_count], 'r--', label='Perfect prediction')\n",
    "    ax.set_xlabel('True Count')\n",
    "    ax.set_ylabel('Predicted Count')\n",
    "    ax.set_title('Count Prediction Accuracy')\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Existence probability distribution\n",
    "    ax = axes[1, 0]\n",
    "    all_existence = existence_probs.flatten()\n",
    "    ax.hist(all_existence, bins=50, alpha=0.7, density=True)\n",
    "    ax.axvline(0.5, color='red', linestyle='--', label='Decision threshold (0.5)')\\n    ax.set_xlabel('Existence Probability')\n",
    "    ax.set_ylabel('Density')\n",
    "    ax.set_title('Distribution of Existence Probabilities')\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Count confusion matrix\n",
    "    ax = axes[1, 1]\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    cm = confusion_matrix(true_counts, pred_counts)\n",
    "    im = ax.imshow(cm, interpolation='nearest', cmap='Blues')\n",
    "    ax.set_xlabel('Predicted Count')\n",
    "    ax.set_ylabel('True Count')\n",
    "    ax.set_title('Count Prediction Confusion Matrix')\n",
    "    \n",
    "    # Add text annotations\n",
    "    thresh = cm.max() / 2.\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            ax.text(j, i, format(cm[i, j], 'd'),\n",
    "                   ha=\"center\", va=\"center\",\n",
    "                   color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    \n",
    "    plt.colorbar(im, ax=ax)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Calculate metrics\n",
    "    count_accuracy = np.mean(true_counts == pred_counts)\n",
    "    count_mae = np.mean(np.abs(true_counts - pred_counts))\n",
    "    \n",
    "    print(f\"\\nðŸ“Š Lattice Count Metrics:\")\n",
    "    print(f\"  Count Accuracy: {count_accuracy:.3f}\")\n",
    "    print(f\"  Count MAE: {count_mae:.3f}\")\n",
    "    print(f\"  True count range: {np.min(true_counts)} - {np.max(true_counts)}\")\n",
    "    print(f\"  Pred count range: {np.min(pred_counts)} - {np.max(pred_counts)}\")\n",
    "    print(f\"  Existence prob range: {np.min(all_existence):.3f} - {np.max(all_existence):.3f}\")\n",
    "\n",
    "# Run the lattice count analysis if we have a trained model\n",
    "if 'model' in locals() and model is not None:\n",
    "    lattice_count_analysis(model, data_loader, num_samples=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc2b9593",
   "metadata": {},
   "outputs": [],
   "source": [
    "def enhanced_training_analysis(history):\n",
    "    \"\"\"\n",
    "    Enhanced analysis of training dynamics with detailed plots\n",
    "    \"\"\"\n",
    "    if history is None:\n",
    "        print(\"âŒ No training history available\")\n",
    "        return\n",
    "        \n",
    "    print(\"ðŸ“ˆ Enhanced Training Dynamics Analysis\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Create comprehensive training plots\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(20, 12))\n",
    "    \n",
    "    # 1. Loss curves with log scale\n",
    "    ax = axes[0, 0]\n",
    "    epochs = range(1, len(history.history['loss']) + 1)\n",
    "    ax.semilogy(epochs, history.history['loss'], 'b-', label='Training Loss', linewidth=2)\n",
    "    ax.semilogy(epochs, history.history['val_loss'], 'r-', label='Validation Loss', linewidth=2)\n",
    "    ax.set_xlabel('Epoch')\n",
    "    ax.set_ylabel('Loss (log scale)')\n",
    "    ax.set_title('Training and Validation Loss (Log Scale)')\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 2. MAE curves\n",
    "    ax = axes[0, 1]\n",
    "    ax.plot(epochs, history.history['mae'], 'b-', label='Training MAE', linewidth=2)\n",
    "    ax.plot(epochs, history.history['val_mae'], 'r-', label='Validation MAE', linewidth=2)\n",
    "    ax.set_xlabel('Epoch')\n",
    "    ax.set_ylabel('Mean Absolute Error')\n",
    "    ax.set_title('Training and Validation MAE')\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 3. Overfitting analysis\n",
    "    ax = axes[0, 2]\n",
    "    val_gap = np.array(history.history['val_loss']) - np.array(history.history['loss'])\n",
    "    ax.plot(epochs, val_gap, 'g-', linewidth=2)\n",
    "    ax.axhline(y=0, color='k', linestyle='--', alpha=0.5)\n",
    "    ax.set_xlabel('Epoch')\n",
    "    ax.set_ylabel('Validation - Training Loss')\n",
    "    ax.set_title('Overfitting Indicator')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 4. Learning rate (if available)\n",
    "    ax = axes[1, 0]\n",
    "    if 'lr' in history.history:\n",
    "        ax.semilogy(epochs, history.history['lr'], 'purple', linewidth=2)\n",
    "        ax.set_xlabel('Epoch')\n",
    "        ax.set_ylabel('Learning Rate (log scale)')\n",
    "        ax.set_title('Learning Rate Schedule')\n",
    "    else:\n",
    "        ax.text(0.5, 0.5, 'Learning Rate\\\\nNot Tracked', transform=ax.transAxes, \n",
    "                ha='center', va='center', fontsize=12)\n",
    "        ax.set_title('Learning Rate Schedule')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 5. Loss improvement rate\n",
    "    ax = axes[1, 1]\n",
    "    loss_diff = -np.diff(history.history['loss'])  # Negative because we want improvement (decrease)\n",
    "    val_loss_diff = -np.diff(history.history['val_loss'])\n",
    "    \n",
    "    ax.plot(epochs[1:], loss_diff, 'b-', label='Training Improvement', linewidth=2)\n",
    "    ax.plot(epochs[1:], val_loss_diff, 'r-', label='Validation Improvement', linewidth=2)\n",
    "    ax.axhline(y=0, color='k', linestyle='--', alpha=0.5)\n",
    "    ax.set_xlabel('Epoch')\n",
    "    ax.set_ylabel('Loss Improvement')\n",
    "    ax.set_title('Per-Epoch Loss Improvement')\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 6. Training stability (rolling metrics)\n",
    "    ax = axes[1, 2]\n",
    "    window_size = min(5, len(epochs) // 4)\n",
    "    if window_size >= 2:\n",
    "        # Rolling standard deviation of loss\n",
    "        train_loss_std = pd.Series(history.history['loss']).rolling(window=window_size).std()\n",
    "        val_loss_std = pd.Series(history.history['val_loss']).rolling(window=window_size).std()\n",
    "        \n",
    "        ax.plot(epochs, train_loss_std, 'b-', label='Training Loss Std', linewidth=2)\n",
    "        ax.plot(epochs, val_loss_std, 'r-', label='Validation Loss Std', linewidth=2)\n",
    "        ax.set_xlabel('Epoch')\n",
    "        ax.set_ylabel('Rolling Standard Deviation')\n",
    "        ax.set_title(f'Training Stability (Window: {window_size})')\n",
    "        ax.legend()\n",
    "    else:\n",
    "        ax.text(0.5, 0.5, 'Not enough\\\\nepochs for\\\\nstability analysis', \n",
    "                transform=ax.transAxes, ha='center', va='center')\n",
    "        ax.set_title('Training Stability')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Print detailed training statistics\n",
    "    print(f\"\\\\nðŸ“Š Training Summary:\")\n",
    "    print(f\"  Total epochs: {len(epochs)}\")\n",
    "    print(f\"  Final train loss: {history.history['loss'][-1]:.6f}\")\n",
    "    print(f\"  Final val loss: {history.history['val_loss'][-1]:.6f}\")\n",
    "    print(f\"  Best val loss: {min(history.history['val_loss']):.6f} (epoch {np.argmin(history.history['val_loss'])+1})\")\n",
    "    print(f\"  Final train MAE: {history.history['mae'][-1]:.6f}\")\n",
    "    print(f\"  Final val MAE: {history.history['val_mae'][-1]:.6f}\")\n",
    "    print(f\"  Best val MAE: {min(history.history['val_mae']):.6f} (epoch {np.argmin(history.history['val_mae'])+1})\")\n",
    "    \n",
    "    # Overfitting analysis\n",
    "    final_gap = history.history['val_loss'][-1] - history.history['loss'][-1]\n",
    "    print(f\"  Final overfitting gap: {final_gap:.6f}\")\n",
    "    \n",
    "    if final_gap > 0.1:\n",
    "        print(\"  âš ï¸  Warning: Significant overfitting detected\")\n",
    "    elif final_gap > 0.05:\n",
    "        print(\"  âš¡ Mild overfitting detected\")\n",
    "    else:\n",
    "        print(\"  âœ… Good generalization\")\n",
    "\n",
    "# Import pandas if not already imported\n",
    "try:\n",
    "    import pandas as pd\n",
    "except ImportError:\n",
    "    print(\"Installing pandas for enhanced analysis...\")\n",
    "    !pip install pandas\n",
    "\n",
    "# Run the enhanced training analysis if we have history\n",
    "if 'history' in locals() and history is not None:\n",
    "    enhanced_training_analysis(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26d7fe3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def interactive_model_exploration(model, image_size=128):\n",
    "    \"\"\"\n",
    "    Interactive exploration of model behavior with custom generated patterns\n",
    "    \"\"\"\n",
    "    print(\"ðŸŽ® Interactive Model Exploration\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Test different pattern complexities\n",
    "    test_cases = [\n",
    "        # Simple cases\n",
    "        {\"name\": \"Single Lattice\", \"params\": [[np.pi/4, 20, 0, 0, 3] + [0]*35]},\n",
    "        {\"name\": \"Two Lattices\", \"params\": [[0, 25, 0, 0, 2, np.pi/2, 30, np.pi, np.pi/2, 2.5] + [0]*30]},\n",
    "        \n",
    "        # Complex cases\n",
    "        {\"name\": \"Dense Pattern\", \"params\": [[0, 15, 0, 0, 1.5, np.pi/3, 18, np.pi/2, 0, 2, np.pi/6, 22, np.pi, np.pi/3, 1.8] + [0]*25]},\n",
    "        \n",
    "        # Edge cases\n",
    "        {\"name\": \"Large Spacing\", \"params\": [[0, 60, 0, 0, 8] + [0]*35]},  # Very coarse pattern\n",
    "        {\"name\": \"Small Spacing\", \"params\": [[0, 8, 0, 0, 1] + [0]*35]},   # Very fine pattern\n",
    "        {\"name\": \"Rotated\", \"params\": [[np.pi/6, 25, 0, 0, 3, np.pi/3, 25, np.pi/4, np.pi/4, 3] + [0]*30]},  # Strong rotation\n",
    "    ]\n",
    "    \n",
    "    fig, axes = plt.subplots(len(test_cases), 4, figsize=(20, 5*len(test_cases)))\n",
    "    if len(test_cases) == 1:\n",
    "        axes = axes.reshape(1, -1)\n",
    "    \n",
    "    for case_idx, test_case in enumerate(test_cases):\n",
    "        # Generate test image\n",
    "        params_tensor = tf.constant([test_case[\"params\"]], dtype=tf.float32)\n",
    "        test_image = hole_based_renderer(params_tensor, image_size=image_size)\n",
    "        \n",
    "        # Get model prediction\n",
    "        prediction = model.predict(test_image, verbose=0)\n",
    "        reconstructed = hole_based_renderer(prediction, image_size=image_size)\n",
    "        \n",
    "        # Plot original\n",
    "        axes[case_idx, 0].imshow(test_image[0, :, :, 0], cmap='gray', vmin=0, vmax=1)\n",
    "        axes[case_idx, 0].set_title(f'{test_case[\"name\"]}\\\\nOriginal')\n",
    "        axes[case_idx, 0].axis('off')\n",
    "        \n",
    "        # Plot reconstruction\n",
    "        axes[case_idx, 1].imshow(reconstructed[0, :, :, 0], cmap='gray', vmin=0, vmax=1)\n",
    "        axes[case_idx, 1].set_title('Reconstruction')\n",
    "        axes[case_idx, 1].axis('off')\n",
    "        \n",
    "        # Plot difference\n",
    "        diff = np.abs(test_image[0, :, :, 0] - reconstructed[0, :, :, 0])\n",
    "        im = axes[case_idx, 2].imshow(diff, cmap='Reds')\n",
    "        axes[case_idx, 2].set_title(f'Difference\\\\nMAE: {np.mean(diff):.4f}')\n",
    "        axes[case_idx, 2].axis('off')\n",
    "        plt.colorbar(im, ax=axes[case_idx, 2], fraction=0.046, pad=0.04)\n",
    "        \n",
    "        # Parameter comparison\n",
    "        true_params = np.array(test_case[\"params\"])\n",
    "        pred_params = prediction[0]\n",
    "        \n",
    "        # Count active lattices\n",
    "        true_active = np.sum(true_params[1::5] > 0.5)\n",
    "        pred_active = np.sum(pred_params[1::5] > 0.5)\n",
    "        \n",
    "        # Show parameter comparison for first few lattices\n",
    "        axes[case_idx, 3].axis('off')\n",
    "        param_text = f\"Active Lattices:\\\\nTrue: {true_active}, Pred: {pred_active}\\\\n\\\\n\"\n",
    "        \n",
    "        param_names = ['Î¸', 'sp', 'Ï†x', 'Ï†y', 'hr']\n",
    "        for lat_idx in range(min(3, true_active)):  # Show first 3 active lattices\n",
    "            param_text += f\"Lattice {lat_idx+1}:\\\\n\"\n",
    "            for p_idx, p_name in enumerate(param_names):\n",
    "                true_val = true_params[lat_idx*5 + p_idx]\n",
    "                pred_val = pred_params[lat_idx*5 + p_idx]\n",
    "                param_text += f\"  {p_name}: {true_val:.2f} â†’ {pred_val:.2f}\\\\n\"\n",
    "            param_text += \"\\\\n\"\n",
    "        \n",
    "        axes[case_idx, 3].text(0.05, 0.95, param_text, transform=axes[case_idx, 3].transAxes,\n",
    "                              verticalalignment='top', fontfamily='monospace', fontsize=8)\n",
    "        axes[case_idx, 3].set_title('Parameter Comparison')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Statistical summary of test cases\n",
    "    print(\"\\\\nðŸ“Š Test Case Performance Summary:\")\n",
    "    for case_idx, test_case in enumerate(test_cases):\n",
    "        params_tensor = tf.constant([test_case[\"params\"]], dtype=tf.float32)\n",
    "        test_image = hole_based_renderer(params_tensor, image_size=image_size)\n",
    "        prediction = model.predict(test_image, verbose=0)\n",
    "        reconstructed = hole_based_renderer(prediction, image_size=image_size)\n",
    "        \n",
    "        mae = np.mean(np.abs(test_image - reconstructed))\n",
    "        mse = np.mean((test_image - reconstructed)**2)\n",
    "        \n",
    "        true_params = np.array(test_case[\"params\"])\n",
    "        param_mae = np.mean(np.abs(true_params - prediction[0]))\n",
    "        \n",
    "        print(f\"  {test_case['name']:15s}: Img MAE={mae:.4f}, Img MSE={mse:.6f}, Param MAE={param_mae:.4f}\")\n",
    "\n",
    "# Run interactive exploration if we have a trained model\n",
    "if 'model' in locals() and model is not None:\n",
    "    interactive_model_exploration(model, image_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1b4289a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def robustness_analysis(model, data_loader, image_size=128):\n",
    "    \"\"\"\n",
    "    Test model robustness to noise and image degradation\n",
    "    \"\"\"\n",
    "    print(\"ðŸ›¡ï¸ Model Robustness and Noise Sensitivity Analysis\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Get some test images\n",
    "    val_dataset = data_loader.create_tf_dataset(batch_size=32, validation_split=0.2)[1]\n",
    "    val_batch = next(iter(val_dataset))\n",
    "    test_images, test_params = val_batch\n",
    "    \n",
    "    # Select a few representative images\n",
    "    num_test = 5\n",
    "    original_images = test_images[:num_test]\n",
    "    original_params = test_params[:num_test]\n",
    "    \n",
    "    # Define noise levels and types\n",
    "    noise_levels = [0.0, 0.05, 0.1, 0.2, 0.3]\n",
    "    noise_types = [\n",
    "        (\"Gaussian\", lambda img, level: img + np.random.normal(0, level, img.shape)),\n",
    "        (\"Salt & Pepper\", lambda img, level: add_salt_pepper_noise(img, level)),\n",
    "        (\"Blur\", lambda img, level: apply_gaussian_blur(img, level)),\n",
    "    ]\n",
    "    \n",
    "    # Helper functions for noise\n",
    "    def add_salt_pepper_noise(image, noise_level):\n",
    "        noisy = image.copy()\n",
    "        # Salt noise\n",
    "        num_salt = int(noise_level * image.size * 0.5)\n",
    "        coords = [np.random.randint(0, i - 1, num_salt) for i in image.shape]\n",
    "        noisy[coords[0], coords[1], coords[2], coords[3]] = 1\n",
    "        \n",
    "        # Pepper noise\n",
    "        num_pepper = int(noise_level * image.size * 0.5)\n",
    "        coords = [np.random.randint(0, i - 1, num_pepper) for i in image.shape]\n",
    "        noisy[coords[0], coords[1], coords[2], coords[3]] = 0\n",
    "        return np.clip(noisy, 0, 1)\n",
    "    \n",
    "    def apply_gaussian_blur(image, blur_level):\n",
    "        from scipy.ndimage import gaussian_filter\n",
    "        blurred = np.zeros_like(image)\n",
    "        for i in range(image.shape[0]):\n",
    "            blurred[i, :, :, 0] = gaussian_filter(image[i, :, :, 0], sigma=blur_level*2)\n",
    "        return blurred\n",
    "    \n",
    "    # Test robustness\n",
    "    results = {}\n",
    "    \n",
    "    for noise_name, noise_func in noise_types:\n",
    "        print(f\"\\\\n Testing {noise_name} noise...\")\n",
    "        results[noise_name] = {\n",
    "            'levels': noise_levels,\n",
    "            'param_maes': [],\n",
    "            'recon_maes': [],\n",
    "            'param_stds': [],\n",
    "            'recon_stds': []\n",
    "        }\n",
    "        \n",
    "        for noise_level in noise_levels:\n",
    "            param_errors = []\n",
    "            recon_errors = []\n",
    "            \n",
    "            for test_idx in range(num_test):\n",
    "                # Add noise to image\n",
    "                if noise_level == 0:\n",
    "                    noisy_image = original_images[test_idx:test_idx+1]\n",
    "                else:\n",
    "                    noisy_image = noise_func(original_images[test_idx:test_idx+1], noise_level)\n",
    "                    noisy_image = np.clip(noisy_image, 0, 1)\n",
    "                \n",
    "                # Get prediction\n",
    "                pred_params = model.predict(noisy_image, verbose=0)\n",
    "                \n",
    "                # Render reconstruction\n",
    "                reconstructed = hole_based_renderer(pred_params, image_size=image_size)\n",
    "                \n",
    "                # Calculate errors\n",
    "                param_error = np.mean(np.abs(original_params[test_idx].numpy() - pred_params[0]))\n",
    "                recon_error = np.mean(np.abs(original_images[test_idx] - reconstructed[0]))\n",
    "                \n",
    "                param_errors.append(param_error)\n",
    "                recon_errors.append(recon_error)\n",
    "            \n",
    "            # Store statistics\n",
    "            results[noise_name]['param_maes'].append(np.mean(param_errors))\n",
    "            results[noise_name]['recon_maes'].append(np.mean(recon_errors))\n",
    "            results[noise_name]['param_stds'].append(np.std(param_errors))\n",
    "            results[noise_name]['recon_stds'].append(np.std(recon_errors))\n",
    "    \n",
    "    # Plot results\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "    \n",
    "    # Parameter error vs noise level\n",
    "    ax = axes[0, 0]\n",
    "    for noise_name in results:\n",
    "        ax.errorbar(results[noise_name]['levels'], results[noise_name]['param_maes'],\n",
    "                   yerr=results[noise_name]['param_stds'], label=noise_name, \n",
    "                   marker='o', linewidth=2, capsize=5)\n",
    "    ax.set_xlabel('Noise Level')\n",
    "    ax.set_ylabel('Parameter MAE')\n",
    "    ax.set_title('Parameter Prediction Robustness')\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Reconstruction error vs noise level\n",
    "    ax = axes[0, 1]\n",
    "    for noise_name in results:\n",
    "        ax.errorbar(results[noise_name]['levels'], results[noise_name]['recon_maes'],\n",
    "                   yerr=results[noise_name]['recon_stds'], label=noise_name,\n",
    "                   marker='s', linewidth=2, capsize=5)\n",
    "    ax.set_xlabel('Noise Level')\n",
    "    ax.set_ylabel('Reconstruction MAE')\n",
    "    ax.set_title('Image Reconstruction Robustness')\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Example noisy images\n",
    "    ax = axes[1, 0]\n",
    "    example_img = original_images[0:1]\n",
    "    \n",
    "    # Create a montage of noisy versions\n",
    "    noise_examples = []\n",
    "    for level in [0.0, 0.1, 0.2]:\n",
    "        for noise_name, noise_func in noise_types[:2]:  # Just Gaussian and S&P\n",
    "            if level == 0:\n",
    "                noisy = example_img\n",
    "            else:\n",
    "                noisy = noise_func(example_img, level)\n",
    "                noisy = np.clip(noisy, 0, 1)\n",
    "            noise_examples.append(noisy[0, :, :, 0])\n",
    "    \n",
    "    # Create montage\n",
    "    montage = np.hstack([np.vstack(noise_examples[i::2]) for i in range(2)])\n",
    "    ax.imshow(montage, cmap='gray')\n",
    "    ax.set_title('Example Noise Effects\\\\n(Left: Gaussian, Right: Salt&Pepper)')\n",
    "    ax.axis('off')\n",
    "    \n",
    "    # Robustness summary\n",
    "    ax = axes[1, 1]\n",
    "    ax.axis('off')\n",
    "    \n",
    "    # Calculate robustness scores (inverse of degradation)\n",
    "    summary_text = \"ðŸ›¡ï¸ ROBUSTNESS SUMMARY\\\\n\\\\n\"\n",
    "    \n",
    "    for noise_name in results:\n",
    "        param_degradation = results[noise_name]['param_maes'][-1] / results[noise_name]['param_maes'][0]\n",
    "        recon_degradation = results[noise_name]['recon_maes'][-1] / results[noise_name]['recon_maes'][0]\n",
    "        \n",
    "        summary_text += f\"{noise_name}:\\\\n\"\n",
    "        summary_text += f\"  Param degradation: {param_degradation:.2f}x\\\\n\"\n",
    "        summary_text += f\"  Recon degradation: {recon_degradation:.2f}x\\\\n\\\\n\"\n",
    "    \n",
    "    # Overall robustness assessment\n",
    "    avg_param_degradation = np.mean([results[name]['param_maes'][-1] / results[name]['param_maes'][0] \n",
    "                                    for name in results])\n",
    "    \n",
    "    if avg_param_degradation < 2.0:\n",
    "        summary_text += \"âœ… EXCELLENT robustness\"\n",
    "    elif avg_param_degradation < 3.0:\n",
    "        summary_text += \"âš¡ GOOD robustness\"\n",
    "    elif avg_param_degradation < 5.0:\n",
    "        summary_text += \"âš ï¸  MODERATE robustness\"\n",
    "    else:\n",
    "        summary_text += \"âŒ POOR robustness\"\n",
    "    \n",
    "    ax.text(0.05, 0.95, summary_text, transform=ax.transAxes,\n",
    "            verticalalignment='top', fontfamily='monospace', fontsize=10)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Run robustness analysis if we have a trained model\n",
    "if 'model' in locals() and model is not None:\n",
    "    robustness_results = robustness_analysis(model, data_loader, image_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "474732ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def comprehensive_evaluation_summary(model, history, data_loader):\n",
    "    \"\"\"\n",
    "    Generate a comprehensive summary of all model evaluations\n",
    "    \"\"\"\n",
    "    print(\"ðŸŽ¯ COMPREHENSIVE MODEL EVALUATION SUMMARY\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    if model is None:\n",
    "        print(\"âŒ No trained model available for evaluation\")\n",
    "        return\n",
    "    \n",
    "    # Quick performance test\n",
    "    val_dataset = data_loader.create_tf_dataset(batch_size=32, validation_split=0.2)[1]\n",
    "    val_batch = next(iter(val_dataset))\n",
    "    val_images, val_params = val_batch\n",
    "    \n",
    "    # Generate predictions for summary\n",
    "    predictions = model.predict(val_images[:20], verbose=0)\n",
    "    reconstructed = hole_based_renderer(predictions, image_size=128)\n",
    "    \n",
    "    # Calculate key metrics\n",
    "    param_mae = np.mean(np.abs(val_params[:20].numpy() - predictions))\n",
    "    recon_mae = np.mean(np.abs(val_images[:20] - reconstructed))\n",
    "    \n",
    "    # Count accuracy\n",
    "    true_counts = [np.sum(val_params[i, 1::5].numpy() > 0.5) for i in range(20)]\n",
    "    pred_counts = [np.sum(predictions[i, 1::5] > 0.5) for i in range(20)]\n",
    "    count_accuracy = np.mean([tc == pc for tc, pc in zip(true_counts, pred_counts)])\n",
    "    \n",
    "    # Model complexity\n",
    "    total_params = model.count_params()\n",
    "    trainable_params = sum([tf.keras.backend.count_params(w) for w in model.trainable_weights])\n",
    "    \n",
    "    print(f\"\\\\nðŸ—ï¸  MODEL ARCHITECTURE:\")\n",
    "    print(f\"   Total parameters: {total_params:,}\")\n",
    "    print(f\"   Trainable parameters: {trainable_params:,}\")\n",
    "    print(f\"   Model size: ~{total_params * 4 / 1024 / 1024:.1f} MB\")\n",
    "    \n",
    "    if history is not None:\n",
    "        print(f\"\\\\nðŸ“ˆ TRAINING PERFORMANCE:\")\n",
    "        print(f\"   Training epochs: {len(history.history['loss'])}\")\n",
    "        print(f\"   Final training loss: {history.history['loss'][-1]:.6f}\")\n",
    "        print(f\"   Final validation loss: {history.history['val_loss'][-1]:.6f}\")\n",
    "        print(f\"   Best validation loss: {min(history.history['val_loss']):.6f}\")\n",
    "        print(f\"   Overfitting gap: {history.history['val_loss'][-1] - history.history['loss'][-1]:.6f}\")\n",
    "    \n",
    "    print(f\"\\\\nðŸŽ¯ PREDICTION ACCURACY:\")\n",
    "    print(f\"   Parameter MAE: {param_mae:.6f}\")\n",
    "    print(f\"   Reconstruction MAE: {recon_mae:.6f}\")\n",
    "    print(f\"   Lattice count accuracy: {count_accuracy:.3f}\")\n",
    "    \n",
    "    # Performance grades\n",
    "    grades = {}\n",
    "    \n",
    "    # Parameter accuracy grade\n",
    "    if param_mae < 0.1:\n",
    "        grades['params'] = 'A+'\n",
    "    elif param_mae < 0.2:\n",
    "        grades['params'] = 'A'\n",
    "    elif param_mae < 0.3:\n",
    "        grades['params'] = 'B'\n",
    "    elif param_mae < 0.5:\n",
    "        grades['params'] = 'C'\n",
    "    else:\n",
    "        grades['params'] = 'D'\n",
    "    \n",
    "    # Reconstruction grade\n",
    "    if recon_mae < 0.05:\n",
    "        grades['recon'] = 'A+'\n",
    "    elif recon_mae < 0.1:\n",
    "        grades['recon'] = 'A'\n",
    "    elif recon_mae < 0.15:\n",
    "        grades['recon'] = 'B'\n",
    "    elif recon_mae < 0.25:\n",
    "        grades['recon'] = 'C'\n",
    "    else:\n",
    "        grades['recon'] = 'D'\n",
    "    \n",
    "    # Count accuracy grade\n",
    "    if count_accuracy > 0.9:\n",
    "        grades['count'] = 'A+'\n",
    "    elif count_accuracy > 0.8:\n",
    "        grades['count'] = 'A'\n",
    "    elif count_accuracy > 0.7:\n",
    "        grades['count'] = 'B'\n",
    "    elif count_accuracy > 0.6:\n",
    "        grades['count'] = 'C'\n",
    "    else:\n",
    "        grades['count'] = 'D'\n",
    "    \n",
    "    print(f\"\\\\nðŸ† PERFORMANCE GRADES:\")\n",
    "    print(f\"   Parameter Prediction: {grades['params']}\")\n",
    "    print(f\"   Image Reconstruction: {grades['recon']}\")\n",
    "    print(f\"   Lattice Count: {grades['count']}\")\n",
    "    \n",
    "    # Overall grade\n",
    "    grade_scores = {'A+': 4.3, 'A': 4.0, 'B': 3.0, 'C': 2.0, 'D': 1.0}\n",
    "    avg_score = np.mean([grade_scores[g] for g in grades.values()])\n",
    "    \n",
    "    if avg_score >= 4.0:\n",
    "        overall = 'A+'\n",
    "        emoji = 'ðŸŒŸ'\n",
    "    elif avg_score >= 3.5:\n",
    "        overall = 'A'\n",
    "        emoji = 'â­'\n",
    "    elif avg_score >= 2.5:\n",
    "        overall = 'B'\n",
    "        emoji = 'ðŸ‘'\n",
    "    elif avg_score >= 2.0:\n",
    "        overall = 'C'\n",
    "        emoji = 'âš¡'\n",
    "    else:\n",
    "        overall = 'D'\n",
    "        emoji = 'âš ï¸'\n",
    "    \n",
    "    print(f\"\\\\n{emoji} OVERALL GRADE: {overall}\")\n",
    "    \n",
    "    # Recommendations\n",
    "    print(f\"\\\\nðŸ’¡ RECOMMENDATIONS:\")\n",
    "    \n",
    "    if param_mae > 0.3:\n",
    "        print(\"   â€¢ Consider longer training or larger model for better parameter accuracy\")\n",
    "    \n",
    "    if recon_mae > 0.15:\n",
    "        print(\"   â€¢ Image reconstruction could be improved with more training data\")\n",
    "    \n",
    "    if count_accuracy < 0.8:\n",
    "        print(\"   â€¢ Lattice count prediction needs improvement - consider adjusting architecture\")\n",
    "    \n",
    "    if history and len(history.history['loss']) < 20:\n",
    "        print(\"   â€¢ Training may have been too short - consider more epochs\")\n",
    "    \n",
    "    if history and (history.history['val_loss'][-1] - history.history['loss'][-1]) > 0.1:\n",
    "        print(\"   â€¢ Model is overfitting - consider regularization or more data\")\n",
    "    \n",
    "    if avg_score >= 3.5:\n",
    "        print(\"   âœ… Model is performing well! Ready for deployment.\")\n",
    "    \n",
    "    print(f\"\\\\n\" + \"=\" * 60)\n",
    "    print(\"ðŸŽ‰ EVALUATION COMPLETE!\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "# Run comprehensive summary\n",
    "if 'model' in locals():\n",
    "    comprehensive_evaluation_summary(\n",
    "        model if 'model' in locals() else None,\n",
    "        history if 'history' in locals() else None,\n",
    "        data_loader if 'data_loader' in locals() else None\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
