{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "845c2e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Environment Setup and Imports\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import fft\n",
    "from scipy.ndimage import gaussian_filter\n",
    "import cv2\n",
    "import h5py\n",
    "import os\n",
    "import datetime\n",
    "import time\n",
    "from math import pi\n",
    "\n",
    "# Configure TensorFlow for better memory management\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    except RuntimeError as e:\n",
    "        print(f\"GPU configuration error: {e}\")\n",
    "\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "print(f\"NumPy version: {np.__version__}\")\n",
    "print(f\"GPUs available: {len(gpus)}\")\n",
    "for gpu in gpus:\n",
    "    print(f\"  {gpu}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "862ff6a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Project paths and hyperparameters\n",
    "BASE_DIR = os.path.abspath(os.path.join(os.getcwd(), \"stage1\"))\n",
    "DATA_DIR = os.path.join(BASE_DIR, \"data\")\n",
    "MODELS_DIR = os.path.join(BASE_DIR, \"models\")\n",
    "LOGS_DIR = os.path.join(BASE_DIR, \"logs\")\n",
    "\n",
    "os.makedirs(DATA_DIR, exist_ok=True)\n",
    "os.makedirs(MODELS_DIR, exist_ok=True)\n",
    "os.makedirs(LOGS_DIR, exist_ok=True)\n",
    "\n",
    "# Image and dataset sizes\n",
    "IMG_SIZE = 64\n",
    "N_CHANNELS = 2\n",
    "N_CLASSES = 4  # 0=square,1=rect,2=tri,3=oblique\n",
    "\n",
    "# Dataset size (adjust as needed)\n",
    "N_TRAIN = 20000\n",
    "N_VAL   = 2000\n",
    "\n",
    "# Rendering and augmentation\n",
    "BLUR_SIGMA = 0.5\n",
    "NOISE_STD  = 0.02\n",
    "\n",
    "# Regression head order: [a_hat, b_hat, r_hat, sin_gamma, cos_gamma, sin_theta, cos_theta, x0_hat, y0_hat]\n",
    "PARAM_DIM = 9\n",
    "\n",
    "# Ranges (normalized by IMG_SIZE for lengths)\n",
    "A_MIN, A_MAX = 6/IMG_SIZE, 18/IMG_SIZE\n",
    "B_MIN, B_MAX = 6/IMG_SIZE, 18/IMG_SIZE\n",
    "R_MIN, R_MAX = 1.5/IMG_SIZE, 5.0/IMG_SIZE\n",
    "\n",
    "DATASET_PATH = os.path.join(DATA_DIR, \"stage1_synth.h5\")\n",
    "\n",
    "rng = np.random.default_rng(1234)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03b51fbe",
   "metadata": {},
   "source": [
    "### Lattice utilities and renderer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56e28712",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Simple canonicalization and geometry helpers\n",
    "def canonicalize_type_and_params(lattice_type, a, b, gamma):\n",
    "    # Square: a=b, gamma=90 deg. Rect: gamma=90 deg, a>=b. Tri: a=b, gamma=60 deg. Oblique: a>=b and gamma in (10,170).\n",
    "    if lattice_type == 0:  # square\n",
    "        a = b = (a + b) * 0.5\n",
    "        gamma = np.deg2rad(90.0)\n",
    "    elif lattice_type == 1:  # rectangular\n",
    "        gamma = np.deg2rad(90.0)\n",
    "        if b > a:\n",
    "            a, b = b, a\n",
    "    elif lattice_type == 2:  # triangular\n",
    "        a = b = (a + b) * 0.5\n",
    "        gamma = np.deg2rad(60.0)\n",
    "    else:  # oblique\n",
    "        if b > a:\n",
    "            a, b = b, a\n",
    "        gamma = np.clip(gamma, np.deg2rad(10.0), np.deg2rad(170.0))\n",
    "    return lattice_type, a, b, gamma\n",
    "\n",
    "\n",
    "def sample_params_one(rng):\n",
    "    \"\"\"Sample random lattice parameters for one sample.\"\"\"\n",
    "    # Random lattice type\n",
    "    lattice_type = rng.integers(0, N_CLASSES)\n",
    "    \n",
    "    # Random lattice parameters (in pixels)\n",
    "    a_px = rng.uniform(A_MIN * IMG_SIZE, A_MAX * IMG_SIZE)\n",
    "    b_px = rng.uniform(B_MIN * IMG_SIZE, B_MAX * IMG_SIZE)\n",
    "    \n",
    "    # Random angle gamma based on lattice type\n",
    "    if lattice_type == 0:  # square\n",
    "        gamma = np.deg2rad(90.0)\n",
    "    elif lattice_type == 1:  # rectangular\n",
    "        gamma = np.deg2rad(90.0)\n",
    "    elif lattice_type == 2:  # triangular\n",
    "        gamma = np.deg2rad(60.0)\n",
    "    else:  # oblique\n",
    "        gamma = rng.uniform(np.deg2rad(10.0), np.deg2rad(170.0))\n",
    "    \n",
    "    # Canonicalize parameters\n",
    "    lattice_type, a_px, b_px, gamma = canonicalize_type_and_params(lattice_type, a_px, b_px, gamma)\n",
    "    \n",
    "    # Random global rotation\n",
    "    theta = rng.uniform(0, 2*np.pi)\n",
    "    \n",
    "    # Random origin offset (in cell coordinates, typically [0,1))\n",
    "    x0_cell = rng.uniform(0, 1)\n",
    "    y0_cell = rng.uniform(0, 1)\n",
    "    \n",
    "    # Random disk radius\n",
    "    r_px = rng.uniform(R_MIN * IMG_SIZE, R_MAX * IMG_SIZE)\n",
    "    \n",
    "    return lattice_type, a_px, b_px, gamma, theta, x0_cell, y0_cell, r_px\n",
    "\n",
    "\n",
    "def primitive_vectors(lattice_type, a, b, gamma):\n",
    "    # Primitive vectors in cell frame (before global rotation)\n",
    "    ax, ay = a, 0.0\n",
    "    bx, by = b*np.cos(gamma), b*np.sin(gamma)\n",
    "    A = np.array([[ax, ay],\n",
    "                  [bx, by]], dtype=np.float32)\n",
    "    return A\n",
    "\n",
    "\n",
    "def apply_global_rotation(A, theta):\n",
    "    # Applies a global rotation by theta to the 2x2 primitive matrix A\n",
    "    c, s = np.cos(theta), np.sin(theta)\n",
    "    R = np.array([[c, -s],\n",
    "                  [s,  c]], dtype=np.float32)\n",
    "    return A @ R.T\n",
    "\n",
    "\n",
    "def render_lattice_image(H, W, lattice_type, a_px, b_px, gamma, theta, x0, y0, radius_px,\n",
    "                         blur_sigma=0.5, noise_std=0.02):\n",
    "    # Render disk lattice image of size HxW (float32 in 0..1)\n",
    "    A = primitive_vectors(lattice_type, a_px, b_px, gamma)\n",
    "    A = apply_global_rotation(A, theta)\n",
    "\n",
    "    v0 = A[0]; v1 = A[1]\n",
    "    avg_step = 0.5*(np.linalg.norm(v0) + np.linalg.norm(v1))\n",
    "    pad = int(2*avg_step + 3*radius_px)\n",
    "\n",
    "    corners = np.array([[ -pad, -pad],\n",
    "                        [ -pad, W+pad],\n",
    "                        [ H+pad, -pad],\n",
    "                        [ H+pad, W+pad]], dtype=np.float32)\n",
    "\n",
    "    origin_px = np.array([x0, y0], dtype=np.float32) @ A  # x0,y0 in cell frame\n",
    "    A_inv = np.linalg.pinv(A)\n",
    "    idx_corners = (corners - origin_px) @ A_inv.T\n",
    "    kmin = int(np.floor(np.min(idx_corners[:,0])))-2\n",
    "    kmax = int(np.ceil (np.max(idx_corners[:,0])))+2\n",
    "    lmin = int(np.floor(np.min(idx_corners[:,1])))-2\n",
    "    lmax = int(np.ceil (np.max(idx_corners[:,1])))+2\n",
    "\n",
    "    img = np.zeros((H, W), dtype=np.float32)\n",
    "    rr = int(round(radius_px))\n",
    "    for k in range(kmin, kmax+1):\n",
    "        base_k = k*A[0]\n",
    "        for l in range(lmin, lmax+1):\n",
    "            p = origin_px + base_k + l*A[1]\n",
    "            y, x = int(round(p[1])), int(round(p[0]))\n",
    "            if -3*rr <= x < W+3*rr and -3*rr <= y < H+3*rr:\n",
    "                cv2.circle(img, (x, y), rr, 1.0, thickness=-1, lineType=cv2.LINE_AA)\n",
    "\n",
    "    if blur_sigma and blur_sigma > 0:\n",
    "        # OpenCV GaussianBlur is much faster than scipy.ndimage for small kernels\n",
    "        ksize = max(1, int(blur_sigma*6) | 1)  # odd kernel size ~ 6*sigma\n",
    "        img = cv2.GaussianBlur(img, (ksize, ksize), blur_sigma)\n",
    "\n",
    "    if noise_std and noise_std > 0:\n",
    "        img = np.clip(img + np.random.normal(0.0, noise_std, img.shape).astype(np.float32), 0.0, 1.0)\n",
    "\n",
    "    return img\n",
    "\n",
    "\n",
    "def image_fft_logmag(img):\n",
    "    # Returns log-magnitude FFT (fftshifted), normalized to [0,1]\n",
    "    f = fft.fftshift(fft.fft2(img.astype(np.float32)))\n",
    "    mag = np.log1p(np.abs(f))\n",
    "    mag /= (mag.max() + 1e-8)\n",
    "    return mag.astype(np.float32)\n",
    "\n",
    "\n",
    "def stack_spatial_and_fft(img):\n",
    "    # Stacks spatial image and its FFT magnitude into (H,W,2)\n",
    "    fft_mag = image_fft_logmag(img)\n",
    "    return np.stack([img, fft_mag], axis=-1)\n",
    "\n",
    "\n",
    "def param_vector(lattice_type, a_px, b_px, gamma, theta, r_px, x0_cell, y0_cell, H, W):\n",
    "    # Builds the 9-dim regression target vector (normalized).\n",
    "    a_hat = a_px / IMG_SIZE\n",
    "    b_hat = b_px / IMG_SIZE\n",
    "    r_hat = r_px / IMG_SIZE\n",
    "    sin_g, cos_g = np.sin(gamma), np.cos(gamma)\n",
    "    sin_t, cos_t = np.sin(theta), np.cos(theta)\n",
    "    return np.array([a_hat, b_hat, r_hat, sin_g, cos_g, sin_t, cos_t, x0_cell, y0_cell], dtype=np.float32)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4c2f30e",
   "metadata": {},
   "source": [
    "### Synthetic dataset generation (HDF5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41ac58b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import multiprocessing as mp\n",
    "from functools import partial\n",
    "\n",
    "\n",
    "def _render_one(sample_idx, seed, blur_sigma, noise_std):\n",
    "    # Worker function: independent RNG per sample for reproducibility\n",
    "    rng = np.random.default_rng(seed + sample_idx)\n",
    "    lattice_type, a, b, gamma, theta, x0c, y0c, r = sample_params_one(rng)\n",
    "    img = render_lattice_image(IMG_SIZE, IMG_SIZE, lattice_type, a, b, gamma, theta, x0c, y0c, r,\n",
    "                               blur_sigma=blur_sigma, noise_std=noise_std)\n",
    "    fft_mag = image_fft_logmag(img)\n",
    "    x_img = np.clip(img*255.0, 0, 255).astype(np.uint8)\n",
    "    x_fft = np.clip(fft_mag*255.0, 0, 255).astype(np.uint8)\n",
    "    y_type = np.int8(lattice_type)\n",
    "    y_params = param_vector(lattice_type, a, b, gamma, theta, r, x0c, y0c, IMG_SIZE, IMG_SIZE)\n",
    "    return sample_idx, x_img, x_fft, y_type, y_params\n",
    "\n",
    "\n",
    "def _create_dataset_with_fallback(h5file, name, shape, dtype, compression_primary=\"lzf\", compression_fallback=\"gzip\"):\n",
    "    try:\n",
    "        return h5file.create_dataset(name, shape=shape, dtype=dtype, compression=compression_primary)\n",
    "    except Exception:\n",
    "        return h5file.create_dataset(name, shape=shape, dtype=dtype, compression=compression_fallback)\n",
    "\n",
    "\n",
    "def generate_and_save_h5(path, n_samples, seed=1234, num_workers=None, chunk_size=256):\n",
    "    if os.path.exists(path):\n",
    "        print(f\"Dataset already exists at {path}. Skipping generation.\")\n",
    "        with h5py.File(path, \"r\") as f:\n",
    "            print({k: v.shape for k,v in f.items()})\n",
    "        return\n",
    "\n",
    "    print(f\"Generating {n_samples} samples to {path} ...\")\n",
    "\n",
    "    # Try to use Rich for a nice progress bar; fall back to simple prints if unavailable\n",
    "    try:\n",
    "        from rich.progress import Progress, BarColumn, TextColumn\n",
    "        use_rich = True\n",
    "    except Exception:\n",
    "        use_rich = False\n",
    "\n",
    "    # Determine a timezone-aware UTC object compatible with current Python version\n",
    "    try:\n",
    "        tz_utc = datetime.UTC  # Python 3.11+\n",
    "    except AttributeError:\n",
    "        tz_utc = datetime.timezone.utc\n",
    "\n",
    "    # Decide workers and avoid thread oversubscription in each process\n",
    "    if num_workers is None:\n",
    "        num_workers = max(1, mp.cpu_count() - 1)\n",
    "    if num_workers > 1:\n",
    "        os.environ.setdefault(\"OMP_NUM_THREADS\", \"1\")\n",
    "        os.environ.setdefault(\"MKL_NUM_THREADS\", \"1\")\n",
    "        os.environ.setdefault(\"OPENBLAS_NUM_THREADS\", \"1\")\n",
    "\n",
    "    with h5py.File(path, \"w\") as f:\n",
    "        d_images = _create_dataset_with_fallback(f, \"images\", (n_samples, IMG_SIZE, IMG_SIZE), np.uint8)\n",
    "        d_ffts   = _create_dataset_with_fallback(f, \"ffts\",   (n_samples, IMG_SIZE, IMG_SIZE), np.uint8)\n",
    "        d_types  = f.create_dataset(\"types\",  shape=(n_samples,), dtype=np.int8)\n",
    "        d_params = f.create_dataset(\"params\", shape=(n_samples, 9), dtype=np.float32)\n",
    "\n",
    "        f.attrs[\"IMG_SIZE\"] = IMG_SIZE\n",
    "        f.attrs[\"PARAM_DIM\"] = PARAM_DIM\n",
    "        f.attrs[\"N_CLASSES\"] = N_CLASSES\n",
    "        f.attrs[\"created\"] = datetime.datetime.now(tz_utc).isoformat()\n",
    "\n",
    "        # Parallel generation with buffered batched writes to reduce HDF5 overhead\n",
    "        worker = partial(_render_one, seed=seed, blur_sigma=BLUR_SIGMA, noise_std=NOISE_STD)\n",
    "\n",
    "        # Use fork context on Linux/Jupyter so workers inherit function state without pickling issues\n",
    "        try:\n",
    "            ctx = mp.get_context(\"fork\")\n",
    "        except ValueError:\n",
    "            ctx = mp.get_context()  # fallback to default\n",
    "\n",
    "        if use_rich:\n",
    "            with Progress(\n",
    "                TextColumn(\"Generating samples\"),\n",
    "                BarColumn(),\n",
    "                TextColumn(\"{task.completed}/{task.total}\"),\n",
    "                TextColumn(\"ETA: {task.fields[eta]}\")\n",
    "            ) as progress:\n",
    "                task = progress.add_task(\"gen\", total=n_samples, eta=\"--:--\")\n",
    "                start = time.time()\n",
    "                processed = 0\n",
    "                buffer = []\n",
    "                with ctx.Pool(processes=num_workers) as pool:\n",
    "                    for res in pool.imap_unordered(worker, range(n_samples), chunksize=max(1, chunk_size//max(1, num_workers))):\n",
    "                        buffer.append(res)\n",
    "                        processed += 1\n",
    "                        # Flush in batches\n",
    "                        if len(buffer) >= chunk_size:\n",
    "                            for idx, x_img, x_fft, y_type, y_params in buffer:\n",
    "                                d_images[idx] = x_img\n",
    "                                d_ffts[idx]   = x_fft\n",
    "                                d_types[idx]  = y_type\n",
    "                                d_params[idx] = y_params\n",
    "                            buffer.clear()\n",
    "                        # Update progress and ETA accurately\n",
    "                        elapsed = max(1e-6, time.time() - start)\n",
    "                        rate = processed / elapsed\n",
    "                        remaining = max(0, n_samples - processed)\n",
    "                        eta_sec = int(remaining / max(1e-6, rate))\n",
    "                        mm, ss = divmod(eta_sec, 60)\n",
    "                        progress.update(task, advance=1, eta=f\"{mm:02d}:{ss:02d}\")\n",
    "\n",
    "                    # flush leftovers\n",
    "                    if buffer:\n",
    "                        for idx, x_img, x_fft, y_type, y_params in buffer:\n",
    "                            d_images[idx] = x_img\n",
    "                            d_ffts[idx]   = x_fft\n",
    "                            d_types[idx]  = y_type\n",
    "                            d_params[idx] = y_params\n",
    "                        buffer.clear()\n",
    "        else:\n",
    "            start = time.time()\n",
    "            processed = 0\n",
    "            buffer = []\n",
    "            with ctx.Pool(processes=num_workers) as pool:\n",
    "                for res in pool.imap_unordered(worker, range(n_samples), chunksize=max(1, chunk_size//max(1, num_workers))):\n",
    "                    buffer.append(res)\n",
    "                    processed += 1\n",
    "                    if len(buffer) >= chunk_size:\n",
    "                        for idx, x_img, x_fft, y_type, y_params in buffer:\n",
    "                            d_images[idx] = x_img\n",
    "                            d_ffts[idx]   = x_fft\n",
    "                            d_types[idx]  = y_type\n",
    "                            d_params[idx] = y_params\n",
    "                        buffer.clear()\n",
    "                    if processed % 1000 == 0 or processed == n_samples:\n",
    "                        elapsed = max(1e-6, time.time() - start)\n",
    "                        rate = processed / elapsed\n",
    "                        remaining = n_samples - processed\n",
    "                        eta_sec = int(remaining / max(1e-6, rate))\n",
    "                        mm, ss = divmod(eta_sec, 60)\n",
    "                        print(f\"  {processed}/{n_samples} | ETA {mm:02d}:{ss:02d}\")\n",
    "            if buffer:\n",
    "                for idx, x_img, x_fft, y_type, y_params in buffer:\n",
    "                    d_images[idx] = x_img\n",
    "                    d_ffts[idx]   = x_fft\n",
    "                    d_types[idx]  = y_type\n",
    "                    d_params[idx] = y_params\n",
    "                buffer.clear()\n",
    "\n",
    "    print(\"Done.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f854ad29",
   "metadata": {},
   "source": [
    "### Preview: sample 9x9 grid from freshly generated data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaf6cd5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "generate_and_save_h5(os.path.join(DATA_DIR, \"stage1_synth.h5\"), N_TRAIN + N_VAL, seed=1234)\n",
    "\n",
    "with h5py.File(DATA_DIR + \"/stage1_synth.h5\", \"r\") as f:\n",
    "    imgs = f[\"images\"][:81]\n",
    "    labels = f[\"types\"][:81]\n",
    "\n",
    "fig = plt.figure(figsize=(12,12))\n",
    "for i in range(81):\n",
    "    ax = plt.subplot(9,9,i+1)\n",
    "    ax.imshow(imgs[i], cmap=\"gray\", vmin=0, vmax=255)\n",
    "    ax.set_title(int(labels[i]), fontsize=8)\n",
    "    ax.axis(\"off\")\n",
    "plt.suptitle(\"Stage 1 samples (label = lattice type: 0=square,1=rect,2=tri,3=oblique)\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f708acaa",
   "metadata": {},
   "source": [
    "### tf.data pipeline for HDF5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28e35fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def h5_dataset(path, split=\"train\"):\n",
    "    with h5py.File(path, \"r\") as f:\n",
    "        N = f[\"images\"].shape[0]\n",
    "    n_train = N_TRAIN\n",
    "    idx = np.arange(N)\n",
    "    if split == \"train\":\n",
    "        sel = idx[:n_train]\n",
    "    else:\n",
    "        sel = idx[n_train:n_train+N_VAL]\n",
    "\n",
    "    def gen():\n",
    "        with h5py.File(path, \"r\") as f:\n",
    "            images = f[\"images\"]\n",
    "            ffts   = f[\"ffts\"]\n",
    "            types  = f[\"types\"]\n",
    "            params = f[\"params\"]\n",
    "            for i in sel:\n",
    "                img = images[i].astype(np.float32) / 255.0\n",
    "                fftm = ffts[i].astype(np.float32) / 255.0\n",
    "                x = np.stack([img, fftm], axis=-1)\n",
    "                y_type = tf.one_hot(int(types[i]), depth=N_CLASSES)\n",
    "                y_params = params[i].astype(np.float32)\n",
    "                yield x, {\"type\": y_type, \"params\": y_params}\n",
    "\n",
    "    ds = tf.data.Dataset.from_generator(\n",
    "        gen,\n",
    "        output_signature=(\n",
    "            tf.TensorSpec(shape=(IMG_SIZE, IMG_SIZE, 2), dtype=tf.float32),\n",
    "            {\n",
    "                \"type\":   tf.TensorSpec(shape=(N_CLASSES,), dtype=tf.float32),\n",
    "                \"params\": tf.TensorSpec(shape=(PARAM_DIM,), dtype=tf.float32),\n",
    "            },\n",
    "        ),\n",
    "    )\n",
    "    return ds\n",
    "\n",
    "BATCH_SIZE = 128\n",
    "train_ds = h5_dataset(DATASET_PATH, \"train\").shuffle(4096, reshuffle_each_iteration=True).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "val_ds   = h5_dataset(DATASET_PATH, \"val\").batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92401c2d",
   "metadata": {},
   "source": [
    "### Model: dual-branch CNN (spatial + FFT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "511b2513",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from tensorflow.keras import layers, models, optimizers, callbacks\n",
    "\n",
    "def conv_block(x, filters, k=3, s=1):\n",
    "    x = layers.Conv2D(filters, k, strides=s, padding=\"same\", use_bias=False)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.ReLU()(x)\n",
    "    return x\n",
    "\n",
    "def branch_backbone(inp):\n",
    "    x = conv_block(inp, 32)\n",
    "    x = conv_block(x, 32)\n",
    "    x = conv_block(x, 64, s=2)   # 32x32\n",
    "    x = conv_block(x, 64)\n",
    "    x = conv_block(x, 128, s=2)  # 16x16\n",
    "    x = conv_block(x, 128)\n",
    "    x = conv_block(x, 256, s=2)  # 8x8\n",
    "    x = conv_block(x, 256)\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    return x\n",
    "\n",
    "inp = layers.Input(shape=(IMG_SIZE, IMG_SIZE, 2))\n",
    "spatial = layers.Lambda(lambda t: t[..., :1])(inp)\n",
    "fftmag  = layers.Lambda(lambda t: t[..., 1:])(inp)\n",
    "\n",
    "feat_spatial = branch_backbone(spatial)\n",
    "feat_fft = branch_backbone(fftmag)\n",
    "\n",
    "h = layers.Concatenate()([feat_spatial, feat_fft])\n",
    "h = layers.Dense(256, activation=\"relu\")(h)\n",
    "h = layers.Dense(128, activation=\"relu\")(h)\n",
    "\n",
    "out_type = layers.Dense(N_CLASSES, activation=\"softmax\", name=\"type\")(h)\n",
    "out_params = layers.Dense(PARAM_DIM, activation=\"linear\", name=\"params\")(h)\n",
    "\n",
    "model = models.Model(inputs=inp, outputs={\"type\": out_type, \"params\": out_params})\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88475fa5",
   "metadata": {},
   "source": [
    "### Compile: multi-task losses and callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cc3ced0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "losses = {\n",
    "    \"type\": \"categorical_crossentropy\",\n",
    "    \"params\": \"mse\",\n",
    "}\n",
    "loss_weights = {\"type\": 1.0, \"params\": 1.0}\n",
    "\n",
    "opt = optimizers.Adam(learning_rate=3e-4)\n",
    "model.compile(optimizer=opt, loss=losses, loss_weights=loss_weights, metrics={\"type\": [\"accuracy\"], \"params\": [\"mae\"]})\n",
    "\n",
    "ckpt_dir = os.path.join(MODELS_DIR, \"ckpt_best\")\n",
    "os.makedirs(ckpt_dir, exist_ok=True)\n",
    "\n",
    "cbs = [\n",
    "    callbacks.ModelCheckpoint(os.path.join(ckpt_dir, \"best.weights.h5\"),\n",
    "                              monitor=\"val_type_accuracy\", save_best_only=True, save_weights_only=True, mode=\"max\"),\n",
    "    callbacks.EarlyStopping(monitor=\"val_type_accuracy\", patience=8, restore_best_weights=True, mode=\"max\"),\n",
    "    callbacks.ReduceLROnPlateau(monitor=\"val_type_accuracy\", factor=0.5, patience=4, min_lr=1e-6, mode=\"max\"),\n",
    "    callbacks.TensorBoard(log_dir=os.path.join(LOGS_DIR, \"tensorboard\", datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\"))),\n",
    "]\n",
    "\n",
    "EPOCHS = 25\n",
    "history = model.fit(train_ds, validation_data=val_ds, epochs=EPOCHS, callbacks=cbs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdf04f4b",
   "metadata": {},
   "source": [
    "### Evaluation: numerical metrics and qualitative reconstructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "104963fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def angle_from_sin_cos(s, c):\n",
    "    return np.arctan2(s, c)\n",
    "\n",
    "def reconstruct_from_params(params_vec, lattice_type):\n",
    "    a_hat, b_hat, r_hat, sin_g, cos_g, sin_t, cos_t, x0_hat, y0_hat = params_vec\n",
    "    a_px = float(a_hat * IMG_SIZE)\n",
    "    b_px = float(b_hat * IMG_SIZE)\n",
    "    r_px = float(np.clip(r_hat, 0.5/IMG_SIZE, 0.5) * IMG_SIZE)\n",
    "    gamma = float(angle_from_sin_cos(sin_g, cos_g))\n",
    "    theta = float(angle_from_sin_cos(sin_t, cos_t))\n",
    "    img = render_lattice_image(IMG_SIZE, IMG_SIZE, int(lattice_type), a_px, b_px, gamma, theta, x0_hat, y0_hat, r_px,\n",
    "                               blur_sigma=BLUR_SIGMA, noise_std=0.0)\n",
    "    return img\n",
    "\n",
    "def evaluate_and_visualize(model, n_vis=6):\n",
    "    with h5py.File(DATASET_PATH, \"r\") as f:\n",
    "        sel = np.arange(N_TRAIN, N_TRAIN+N_VAL)\n",
    "        idx = np.random.choice(sel, size=n_vis, replace=False)\n",
    "\n",
    "        imgs = f[\"images\"][idx].astype(np.float32)/255.0\n",
    "        ffts = f[\"ffts\"][idx].astype(np.float32)/255.0\n",
    "        types = f[\"types\"][idx].astype(np.int32)\n",
    "        params_true = f[\"params\"][idx].astype(np.float32)\n",
    "\n",
    "    x_in = np.stack([imgs, ffts], axis=-1)\n",
    "    preds = model.predict(x_in, verbose=0)\n",
    "    type_pred = np.argmax(preds[\"type\"], axis=-1)\n",
    "    params_pred = preds[\"params\"]\n",
    "\n",
    "    def ang_err_deg(s_true, c_true, s_pred, c_pred):\n",
    "        a_true = np.arctan2(s_true, c_true)\n",
    "        a_pred = np.arctan2(s_pred, c_pred)\n",
    "        d = np.rad2deg(np.angle(np.exp(1j*(a_pred - a_true))))\n",
    "        return np.abs(d)\n",
    "\n",
    "    gamma_err = ang_err_deg(params_true[:,3], params_true[:,4], params_pred[:,3], params_pred[:,4]).mean()\n",
    "    theta_err = ang_err_deg(params_true[:,5], params_true[:,6], params_pred[:,5], params_pred[:,6]).mean()\n",
    "    mae_lengths = np.mean(np.abs(params_true[:, :3] - params_pred[:, :3]), axis=0)\n",
    "    mae_offsets = np.mean(np.abs(params_true[:, 7:] - params_pred[:, 7:]), axis=0)\n",
    "    acc = np.mean(type_pred == types)\n",
    "\n",
    "    print(f\"Validation sample accuracy (coarse): {acc:.3f}\")\n",
    "    print(f\"MAE lengths [a_hat, b_hat, r_hat]: {mae_lengths}\")\n",
    "    print(f\"MAE offsets [x0_hat, y0_hat]: {mae_offsets}\")\n",
    "    print(f\"Angle RMSE-ish | gamma: {gamma_err:.2f} deg, theta: {theta_err:.2f} deg\")\n",
    "\n",
    "    n = n_vis\n",
    "    fig = plt.figure(figsize=(9, 4*n))\n",
    "    for i in range(n):\n",
    "        gt_img = imgs[i]\n",
    "        pred_img = reconstruct_from_params(params_pred[i], type_pred[i])\n",
    "        gt_fft = image_fft_logmag(gt_img)\n",
    "        pred_fft = image_fft_logmag(pred_img)\n",
    "\n",
    "        ax = plt.subplot(n, 4, 4*i+1); ax.imshow(gt_img, cmap=\"gray\"); ax.set_title(f\"GT img | type={types[i]}\"); ax.axis(\"off\")\n",
    "        ax = plt.subplot(n, 4, 4*i+2); ax.imshow(pred_img, cmap=\"gray\"); ax.set_title(f\"Pred img | type={type_pred[i]}\"); ax.axis(\"off\")\n",
    "        ax = plt.subplot(n, 4, 4*i+3); ax.imshow(gt_fft, cmap=\"gray\"); ax.set_title(\"GT FFT\"); ax.axis(\"off\")\n",
    "        ax = plt.subplot(n, 4, 4*i+4); ax.imshow(pred_fft, cmap=\"gray\"); ax.set_title(\"Pred FFT\"); ax.axis(\"off\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "evaluate_and_visualize(model, n_vis=6)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a55ef615",
   "metadata": {},
   "source": [
    "### Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80ebd7d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "saved_path = os.path.join(MODELS_DIR, \"saved_model\")\n",
    "model.save(saved_path, include_optimizer=False)\n",
    "print(f\"Saved model to: {saved_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "msl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
